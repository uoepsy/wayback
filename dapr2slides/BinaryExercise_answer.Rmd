---
title: "Exercise 2.6 Answer"
author: "Tom Booth"
date: "06/10/2020"
output: 
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read data into R
The file path used here will depend on where your file is saved, but something like the following will work:

```{r}
library(tidyverse)
```

```{r}
w2 <- read_csv("week2.csv")
head(w2)
```

Look's like the data has read in fine.

# Run the linear model

```{r}
m1 <- lm(Y ~ X, data = w2)
summary(m1)
```

So from this output, we can see the mean of the group coded 0 of `X` is `r round(m1$coefficients[[1]],3)` and the mean of the second group (coded 1) is `r round(m1$coefficients[[2]],3)` , indicating the mean of this group is smaller. To be exact, it is `r round(m1$coefficients[[1]] + m1$coefficients[[2]],3)`

# Run an independent sample t-test

```{r}
m2 <- t.test(Y ~ X, data = w2)
m2
```

So, lets start by confirming the group means. These appear at the bottom of the `t.test` output, and line up with our values reported above. So this is good. 

Now let's look at the t-values. From the `lm` the t-value for the effect of `X` is `r round(summary(m1)$coefficients[2,3],3)` and from the `t.test` the associated value is `r round(m2$statistic,3)`. We do not need to worry about the minus sign. In this instance, this is simply the way the two tests are substracting the group means. Remember the t-distribution is symmetric, so this is showing the same magnitude of difference, but in the case of the linear model it is X=1 - X=0, and for the t-test X=0 - X=1.

Where we do see a small difference is in the p-values. From the linear model, the p-value is `r round(summary(m1)$coefficients[2,4],6)` and from the t.test the p-value is `r round(m2$p.value, 6)`. The difference here is because of the degrees of freedom used in the t.test function, and the specific assumption being made about the variances.

You may recall that an independent sample t-test assumes that the variance of the outcome in both groups is equal. R by default **does not** assume this, and runs what is called a Welch Test, which adjusts the degrees of freedom to take account of any differences in the variance of the outcome across groups. We can see that the impact here is very small. If we want to make the results line up perfectly, we need to tell R to assume variances are equal. We have done this below using the `var.equal = T` command.

```{r}
m3 <- t.test(Y ~ X, data = w2, var.equal = T)
m3
```

In this output, you can see the degrees of freedom are identical to the linear model (N-k-1, or 150-1-1 = 148), and as a result, the p-value is identical to our linear model.