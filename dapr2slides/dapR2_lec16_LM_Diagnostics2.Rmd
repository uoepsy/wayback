---
title: "<b>Week 9: Further diagnostics </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "TOM BOOTH & ALEX DOUMAS"
institute: "Department of Psychology<br>The University of Edinburgh"
date: "AY 2020-2021"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(car)
library(patchwork)
library(kableExtra)

salary2 <- read_csv("./salary2.csv")
```

# Week's Learning Objectives
1. Specify the assumptions underlying a LM with multiple predictors

2. Assess if a fitted model satisfies the assumptions

3. Test and assess the effect of influential cases on LM coefficients and overall model evaluations

---
# Topics for today
+ Recap diagnostics for LM

+ Additional checks with multiple predictors

+ Additional metrics for assessing influential cases.

---
#  Three important features

+ Model outliers
	+ Cases for which there is a large discrepancy between their predicted value ( $\hat{y_i}$ ) and their observed value ( $y_i$ )

--

+ High leverage cases
	+ Cases with an unusual value of the predictor ( $x_i$ )

--

+ High influence cases
	+ Cases who are having a large impact on the estimation of model

---
# Some data for today

.pull-left[
+ Let's look again at our data predicting salary from years or service and performance ratings (no interaction).

$$y_i = \beta_0 + \beta_1 x_{1} + \beta_2 x_{2} + \epsilon_i$$

+ $y$ = Salary (unit = thousands of pounds ).

+ $x_1$ = Years of service.

+ $x_2$ = Average performance ratings.
 
]

.pull-right[

```{r, echo=FALSE}
salary2 %>%
  slice(1:10) %>%
  kable(.) %>%
  kable_styling(full_width = F)
```


]

---
# Our model

```{r}
m1 <- lm(salary ~ serv + perf, data = salary2)
```


---
# Our model

```{r, echo=FALSE}
summary(m1)
```


---
# Influence of coefficients
+ We have already considered Cook's distance as a measure of influence.
  + Cook's distance is a single value summarizing the total influence of a case

+ In the context of a lm with 2+ predictors, we may want to look in a little more detail.

+ **DFFit**: The difference between the predicted outcome value for a case with versus without a case included

+ **DFbeta**: The difference between the value for a coefficient with and without a case included

+ **DFbetas**: A standardised version of DFbeta
  + Obtained by dividing by an estimate of the standard error of the regression coefficient with the case removed

---
# In R

+ We can extract these measures using the `influence.measures()` function:

```{r}
dfs_m1 <- influence.measures(m1)
dfs_m1$infmat[1:10,2:7]
```


---
#  Influence on standard errors 
+ Influential cases can impact the $SE$ as well as the estimation of coefficients.
  + This means it impacts our inferences.

+ Recall, the standard error for a regression slope (single predictor):

$$SE(\beta_1) = \sqrt{\frac{\frac{SSE}{(N-k-1)}}{\sum(x_i  -\bar{x})^2}}$$

+ Where:
	+ $SSE$ is the sum of squared error (i.e. $SS_{residual}$ )
	+ $N$ is the sample size
	+ $k$ is the number of predictors

---
#  Influence on standard errors 

$$SE(\beta_1) = \sqrt{\frac{\frac{SSE}{(N-k-1)}}{\sum(x_i  -\bar{x})^2}}$$

+ $\sum(x_i  -\bar{x})^2$ is the sum of squared deviations from each $X$ value from the mean of $X$

+ This term implies that increasing the variance in $X$ will decrease the standard error of

+ High leverage cases (which are far from the mean of X) can increase $X$ variance

---
#  COVRATIO 
+ Influence on standard errors can be measured using the **COVRATIO** statistic
	+ COVRATIO value <1 show that precision is decreased (SE increased)  by a case
	+ COVRATIO value >1 show that precision is increased (SE decreased) by a case

+ Cases with COVRATIOS $> 1+[3(k +1)/n]$ or $< 1-[3( k +1)/ n ]$ can be considered to have a strong influence on the standard errors

---
#  COVRATIO in R 
+ COVRATIO values can be extracted using the `covratio()` function:

```{r}
cr <- covratio(m1)
cr[1:5]
```


---
#  COVRATIO in R 

+ And we can check cases using the cuts above:

```{r}
which(cr > (1+(3*2)/100))
```


---
# Summary of today

+ Today we have consider:
  + DFFit
  + DFbeta
  + DFbetas
  + COVRATIO

+ These provide more detailed evaluation of the influence of cases on coefficients, model fit, and standard errors (inference) for linear models

---
# Next tasks
+ This week:
  + Complete your lab
  + Come to office hours
  + Weekly quiz - content from week 8
      + Open Monday 09:00
      + Closes Sunday 17:00
