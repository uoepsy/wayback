<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Hypothesis testing</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-plus')) {
    f.classList.add('fa-minus')
    f.classList.remove('fa-plus')
} else {
    f.classList.add('fa-plus')
    f.classList.remove('fa-minus')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="https://uoepsy.github.io/usmr/">
    <span class="fas fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    USMR Starts Here!
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="00_introPG.html">Getting started with R &amp; RStudio</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data &amp; Distributions
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_categorical.html">1: Categorical Data</a>
    </li>
    <li>
      <a href="02_numerical.html">2: Numeric Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tests, Models &amp; Data Wrangling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03_nhst.html">3: Hypothesis testing</a>
    </li>
    <li>
      <a href="04_tests.html">4: More tests</a>
    </li>
    <li>
      <a href="05_covcor.html">5: Cov, Cor, Functions &amp; Models</a>
    </li>
    <li class="dropdown-header">--- 6: Break Week ---</li>
    <li>
      <a href="06_messy.html">7: Messy data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Regression models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="07_slr.html">8: Linear Regression</a>
    </li>
    <li>
      <a href="08_mlr.html">9: More Linear Regression</a>
    </li>
    <li>
      <a href="08b_modelselect.html">Optional Extra: Model Selection</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    More!
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="09_glm.html">10: GLM!</a>
    </li>
    <li>
      <a href="10_sswriting.html">11: Writing up</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Hypothesis testing</h1>

</div>


<!-- :::red -->
<!-- **Preliminaries**   -->
<!-- - Be sure to check the [**solutions to last week's exercises**](02_numerical.html). You can still ask any questions about previous weeks' materials if things aren't clear!    -->
<!-- 1. Open Rstudio, make sure you have the USMR project open, and create a new RMarkdown document (giving it a title for this week).  -->
<!-- ::: -->
<div id="reading-standard-error" class="section level1">
<h1>Reading: Standard error</h1>
<p>Recall what we have seen thus far:</p>
<ul>
<li><p>We can generate a sample of size <span class="math inline">\(n\)</span>, drawn from a population which has a mean of <span class="math inline">\(\mu\)</span> and a standard deviation of <span class="math inline">\(\sigma\)</span>:</p>
<pre class="r"><code># draw random sample of n = 20 from 
# a population with mean 178 and sd 10
rnorm(n = 20, mean = 178, sd = 10)</code></pre></li>
<li><p>And we can calculate the mean of a random sample:</p>
<pre class="r"><code>mean(rnorm(n = 20, mean = 178, sd = 10))</code></pre>
<pre><code>## [1] 182.4367</code></pre></li>
<li><p>We can repeat this process many times (using <code>replicate()</code>), so that we have many sample means:</p>
<pre class="r"><code>manysamplemeans &lt;- replicate(1000, mean(rnorm(n = 20, mean = 178, sd = 10)))
# we now have 1000 sample means
length(manysamplemeans)</code></pre>
<pre><code>## [1] 1000</code></pre></li>
</ul>
<p><strong>Why are we doing this?</strong></p>
<p>What we’re doing here is showing the process of taking many samples of the same size from a population, and calculating a statistic on each sample.<br />
The distribution of these sample statistics shows how they will vary from sample to sample due to chance.</p>
<p>In the above example, for samples of <span class="math inline">\(n=20\)</span> drawn from a population with mean <span class="math inline">\(\mu=178\)</span>, and standard deviation <span class="math inline">\(\sigma=10\)</span>, we’re quite likely to get sample means between 174 and 182, and we’re less likely to see sample means <span class="math inline">\(&lt;174\)</span> and <span class="math inline">\(&gt;182\)</span>.</p>
<pre class="r"><code>hist(manysamplemeans)</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="yellow">
<ul>
<li>The theoretical distribution of how sample statistics will vary on repeated sampling is known as the <strong>sampling distribution</strong>.<br />
</li>
<li>The standard deviation of the sampling distribution is known as the <strong>standard error</strong>.<br />
</li>
<li>Note that the bigger our sample size, the smaller our standard error - i.e., the more precise our sample means are going to be as estimates of the population mean:
<img src="03_nhst_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /></li>
</ul>
</div>
<div id="normal-curves-clt" class="section level2">
<h2>Normal curves &amp; CLT</h2>
<p>Notice that the sampling distributions we have generated above all have similar properties - they are <em>symmetric and bell-shaped</em>. This shape of distribution is known as the <strong>normal</strong> distribution, and we can define a specific distribution via two parameters, the mean and the standard deviation.</p>
<p>In fact, the <strong>central limit theorem (CLT)</strong> states that when we take sufficiently large random samples from a population, the distribution of the sample means will be approximately normally distributed. This holds regardless of whether the population is normal (or skewed).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-6"></span>
<img src="03_nhst_files/figure-html/unnamed-chunk-6-1.png" alt="Population distributions (top) and sampling distributions (bottom)" width="80%" />
<p class="caption">
Figure 1: Population distributions (top) and sampling distributions (bottom)
</p>
</div>
<p>There are certain properties of normal distributions which we can exploit, in order to determine how plausible an observed value is relative to a distribution. When a distribution is normal (symmetric and bell-shaped):</p>
<ul>
<li>68% of values will lie within 1 standard deviation of the mean.</li>
<li>95% of values will lie within 1.96 standard deviations of the mean.</li>
<li>99.7% of values will lie within 3 standard deviations of the mean.</li>
</ul>
<p><img src="images/hypothesis/normal.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="standard-error-in-practice" class="section level2">
<h2>Standard Error in practice</h2>
<p>In practice, we cannot actually draw lots and lots of samples in order to construct a sampling distribution, and we do not know the population parameters which are required to generate samples like we did above (we do not know the population mean <span class="math inline">\(\mu\)</span> or standard deviation <span class="math inline">\(\sigma\)</span>)</p>
<p>Instead, we start with just one observed sample, e.g.:</p>
<pre class="r"><code>observed_sample &lt;- c(176.86, 169.45, 177.93, 175.89, 169.05, 162.56, 189.29, 196.15, 159.45, 165.69, 186.88, 176.9, 188.52, 164.05, 175.62, 180.89, 193.63, 161.59, 182.74, 184.23)</code></pre>
<p>What we <em>can</em> do is either:</p>
<ul>
<li><p><strong>A:</strong> Simulate lots of sampling. We can actually use <em>resampling with replacement</em> from our original sample as a means of imitating repeated sampling. This is known as <strong>Bootstrapping</strong>.</p>
<pre class="r"><code># bootstrap means of resamples with replacement of the same size (20) as observed sample
bootstrap_means &lt;- replicate(1000, mean(sample(observed_sample, size = 20, replace = TRUE)))
# SE = sd of bootstrap resample means 
sd(bootstrap_means)</code></pre>
<pre><code>## [1] 2.432326</code></pre></li>
<li><p>or <strong>B:</strong> Estimate the standard error using a formula:<br />
<span class="math display">\[
SE = \frac{\sigma}{\sqrt{n}}  \\
\quad \\
\begin{align}
&amp; \text{Where} \\
&amp; \sigma = \text{standard deviation} \\
&amp; n = \text{sample size} \\
\end{align}
\]</span>
Note that <span class="math inline">\(\sigma\)</span> is the standard deviation of the population, which is unknown to us.<br />
However, we can use the standard deviation of our sample (<span class="math inline">\(\hat \sigma\)</span> or <span class="math inline">\(s\)</span>) as our estimate of this:</p>
<pre class="r"><code># SE = standard deviation / square root of n
sd(observed_sample)/sqrt(length(observed_sample))</code></pre>
<pre><code>## [1] 2.459404</code></pre></li>
</ul>
</div>
</div>
<div id="reading-hypothesis-testing" class="section level1">
<h1>Reading: Hypothesis testing</h1>
<p>The sampling distribution is at the basis of null hypothesis significance testing.</p>
<p>Recall from the previous lab that we had a dataset on 131 participants who took part in a Stroop Task experiment. Each participant completed a color-naming task in two conditions: Matching and Mismatching. The differences in participants’ times for each condition are taken as indicating the effect of the color-word inteference (we have been calling this the “stroop effect”).</p>
<p>In our observed sample, the stroop effect had a mean <span class="math inline">\(\bar x =\)</span> 2.4 and a standard deviation <span class="math inline">\(s=\)</span> 5.02.</p>
<p>We can theorise about what the sampling distribution of means from samples of size <span class="math inline">\(n=131\)</span> would be like, assuming there to be no stroop effect (i.e., the mean in the population is zero).</p>
<ul>
<li><p>We can estimate the standard error by <em>resampling</em> our data <em>with replacement</em>, to generating many bootstrapped samples of size <span class="math inline">\(n=131\)</span>:</p>
<pre class="r"><code># bootstrap resample means:
many_stroop_means &lt;- replicate(1000, mean(sample(stroopdata$stroop_effect, size = 131, replace = TRUE)))
# standard deviation of 1000 resample means
sd(many_stroop_means)</code></pre>
<pre><code>## [1] 0.4290532</code></pre></li>
<li><p>or we can estimate it by using the sample formula: <span class="math inline">\(\frac{\hat \sigma}{\sqrt{n}} = \frac{5.02}{\sqrt{131}} = 0.439\)</span>.</p></li>
</ul>
<p><br>
Either way, what we get is an idea of the distribution of what we would expect from means from samples of 131, under the hypothesis that there is no “stroop effect” - it will have a mean of 0 and a standard deviation of approximately 0.44.<br />
Against this, we can then compare our observed mean:</p>
<div class="figure" style="text-align: center"><span id="fig:hyp"></span>
<img src="03_nhst_files/figure-html/hyp-1.png" alt="Sampling distribution for mean of sample size 131, assuming population mean = 0. Observed sample mean shown in red" width="80%" />
<p class="caption">
Figure 2: Sampling distribution for mean of sample size 131, assuming population mean = 0. Observed sample mean shown in red
</p>
</div>
<p>What we implicitly have here are two competing hypotheses: the null hypothesis (<span class="math inline">\(H_0\)</span>), and an alternative hypothesis (<span class="math inline">\(H_1\)</span>):</p>
<ul>
<li><span class="math inline">\(H_0: \mu = 0\)</span> The mean “stroop effect” in the population is equal to 0.<br />
</li>
<li><span class="math inline">\(H_1: \mu \neq 0\)</span> The mean “stroop effect” in the population is not equal to 0.</li>
</ul>
<p>We can perform a statistical test against the null hypothesis. Once we have defined our competing hypotheses (above), we decide on the appropriate test; calculate the test-statistic; and then compute the theoretical probability of results as or more extreme than those we observed.</p>
<div class="yellow">
<p><strong>Probability in NHST (null hypothesis significance testing)</strong></p>
<p>Probabilities in NHST are defined as the relative frequency of an event <em>over many trials</em> (as “many” <span class="math inline">\(\to \infty\)</span>).
This requires assuming some features of the data generating process which guides what the “many trials” would look like (e.g., that there is no effect).</p>
<p>A <span class="math inline">\(p\)</span>-value is the probability of observing results as or more extreme than the data, <em>if the data were really generated by a hypothesised chance process</em>.</p>
</div>
<div class="yellow">
<p><strong>Making decisions in NHST</strong></p>
<p>We pre-specify <span class="math inline">\(\alpha\)</span> (“alpha”) - the probability below which we will consider our results to be evidence against the null hypothesis.<br />
e.g.: setting <span class="math inline">\(\alpha = 0.05\)</span> means that if, <em>assuming the null hypothesis to be true</em> we would get a result at least as extreme as the one we observed only 0.05 (5%) of the time or less, then we will reject the null hypothesis.</p>
</div>
<div id="calculating-a-test-statistic" class="section level2">
<h2>Calculating a test statistic</h2>
<p>Performaing an hypothesis test requires calculating a <strong>test statistic</strong>.<br />
For our question (whether the mean stroop effect is different from 0), the appropriate test statistic is a <span class="math inline">\(t\)</span>-statistic, which is used to determine whether a sample mean <span class="math inline">\(\bar x\)</span> is likely to have been generated by a process with a specific theorised mean <span class="math inline">\(\mu_0\)</span>.</p>
<p><span class="math display">\[
t = \frac{\bar x - \mu_0}{\frac{s}{\sqrt{n}}}
\]</span></p>
<p>Think about what each part of the formula represents. The top part <span class="math inline">\(\bar{x}-\mu_0\)</span> is the distance from the observed mean to the hypothesised mean (zero):</p>
<pre class="r"><code>mean(stroopdata$stroop_effect) - 0</code></pre>
<pre><code>## [1] 2.402977</code></pre>
<p>And the bottom part is the standard error - the standard deviation of the sampling distribution:</p>
<pre class="r"><code># SE = sd / sqrt(n)
sd(stroopdata$stroop_effect) / sqrt(length(stroopdata$stroop_effect))</code></pre>
<pre><code>## [1] 0.4382302</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Let’s calculate the <span class="math inline">\(t\)</span>-statistic now:</p>
<pre class="r"><code>t_obs = (mean(stroopdata$stroop_effect) - 0 ) / (sd(stroopdata$stroop_effect)/sqrt(131))
t_obs</code></pre>
<pre><code>## [1] 5.483367</code></pre>
</div>
<div id="computing-the-p-value" class="section level2">
<h2>Computing the p-value</h2>
<p>Now that we have our test statistic, we are able to ask the following question:</p>
<ul>
<li>Assuming the null hypothesis <span class="math inline">\(H_0\)</span> to be true, what is the probability that we observe a test statistic at least as extreme as the one we observed?</li>
</ul>
<p>The sampling distribution of a <span class="math inline">\(t\)</span>-statistic (i.e., the distribution of <span class="math inline">\(t\)</span>-statistics from many many trials) follows a <span class="math inline">\(t\)</span>-distribution. The particular shape of the <span class="math inline">\(t\)</span>-distribution is determined by the <strong>degrees of freedom</strong>. By ‘degrees of freedom’ we refer to the number of independent observations in a set of data.</p>
<p>When we are estimating a mean from a single sample, the degrees of freedom is equal to the sample size minus one. This means that the sampling distribution of <span class="math inline">\(t\)</span>-statistics from samples of size 10, would follow a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(10-1\)</span> degrees of freedom.</p>
<p>You can see the <span class="math inline">\(t\)</span>-distribution for different degrees of freedom below. Notice that as the degrees of freedom (<span class="math inline">\(\nu\)</span> in the plot below) gets bigger (so as <span class="math inline">\(n\)</span> gets bigger), the more the <span class="math inline">\(t\)</span>-distibution fits a normal distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/1024px-Student_t_pdf.svg.png" alt="t distributions. Source: https://en.wikipedia.org/wiki/Student%27s_t-distribution" width="400px" height="300px" />
<p class="caption">
Figure 3: t distributions. Source: <a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution" class="uri">https://en.wikipedia.org/wiki/Student%27s_t-distribution</a>
</p>
</div>
<div class="optional-begin">
Degrees of freedom (df)<span id="opt-start-38" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-38&#39;, &#39;opt-start-38&#39;)"></span>
</div>
<div id="opt-body-38" class="optional-body" style="display: none;">
<p>Suppose we have four unkown numbers (<span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>) which <em>must</em> have a mean of 5.</p>
<p>Do the following, <em>in order:</em></p>
<ol style="list-style-type: decimal">
<li>Choose a value for <span class="math inline">\(a\)</span>.</li>
<li>Choose a value for <span class="math inline">\(b\)</span>.</li>
<li>Choose a value for <span class="math inline">\(c\)</span>.</li>
<li>Can you choose a value for <span class="math inline">\(d\)</span> while ensuring the mean of the four numbers you have chosen is 5?</li>
</ol>
<hr />
<p>You are free to choose anything you like for <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span>.<br />
But once those are fixed, you have no freedom to choose <span class="math inline">\(d\)</span>.</p>
<p>Example:</p>
<ul>
<li><span class="math inline">\(a\)</span> = 1<br />
</li>
<li><span class="math inline">\(b\)</span> = 2<br />
</li>
<li><span class="math inline">\(c\)</span> = 3</li>
</ul>
<p>We know that <span class="math inline">\(\frac{1+2+3+d}{4} = 5\)</span>
So there is only one possible value for <span class="math inline">\(d\)</span>:<br />
<span class="math inline">\(\frac{1+2+3+d}{4} = 5\)</span><br />
<span class="math inline">\(1+2+3+d = 5*4\)</span><br />
<span class="math inline">\(1+2+3+d = 20\)</span><br />
<span class="math inline">\(d = 20-3-2-1\)</span><br />
<span class="math inline">\(d = 14\)</span></p>
</div>
<p class="optional-end">
</p>
<p>We can ask R to calculate what proportion of the <span class="math inline">\(t\)</span>-distribution with 130 (<span class="math inline">\(131-1\)</span>) degrees of freedom is more extreme than the <span class="math inline">\(t\)</span>-statistic we observed.</p>
<pre class="r"><code># our t statistic:
t_obs</code></pre>
<pre><code>## [1] 5.483367</code></pre>
<pre class="r"><code># proportion of distribution to the right
pt(t_obs, df = 130, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 1.046221e-07</code></pre>
<p>As you can see, the resulting value is very small. This tells us that if there is truly no stroop effect, and we took lots and lots of samples of 131 peoples’ responses and calculated a <span class="math inline">\(t\)</span>-statistic for each one of them, then <span class="math inline">\(1.0462207\times 10^{-7}\)</span> of the time we will get a <span class="math inline">\(t\)</span>-statistic <span class="math inline">\(&gt;\)</span> 5.48.</p>
<p>Recall, however, that our alternative hypothesis is that the mean is <strong>not equal</strong> to 0. This means we will reject the null hypothesis if we find a strong stroop effect <em>in either direction</em>.<br />
So we therefore want to calculate the probability of getting a <span class="math inline">\(t\)</span>-statistic as extreme as the one observed <em>in either direction</em>. Because the <span class="math inline">\(t\)</span>-distribution is symmetrical, we can simply multiply the previous bit of code by 2.</p>
<pre class="r"><code>pt(t_obs, df = 130, lower.tail = FALSE) * 2</code></pre>
<pre><code>## [1] 2.092441e-07</code></pre>
<div class="int">
<p>If the null hypothesis were true (the mean stroop effect in the population is zero), then 0.000000209 of random samples of size <span class="math inline">\(n=131\)</span> would result in a <span class="math inline">\(t\)</span>-statistic which is at least as extreme as the one we observed (<span class="math inline">\(\geq 5.48\)</span> or <span class="math inline">\(\leq -5.48\)</span>).</p>
<p>Given that this is less than our pre-specified level (0.05), we will take this as reason to reject the null hypothesis.</p>
</div>
</div>
<div id="letting-r-do-all-the-work" class="section level2">
<h2>Letting R do all the work</h2>
<p>The good news is that we can do all of this without having to go through the rigmarole of manually calculating the test-statistic or computing the p-value.</p>
<p>Pay attention to how the parts of the results of the below match up with our calculations above.</p>
<pre class="r"><code>t.test(stroopdata$stroop_effect, mu = 0)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  stroopdata$stroop_effect
## t = 5.4834, df = 130, p-value = 2.092e-07
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  1.535991 3.269963
## sample estimates:
## mean of x 
##  2.402977</code></pre>
<!-- ```{r echo=FALSE, fig.width=6, fig.height=4} -->
<!-- ggplot(data=tibble(samplemeans),aes(x=samplemeans))+ -->
<!--   geom_histogram(alpha=.1)+ -->
<!--   stat_function(geom="line",fun=~dnorm(.x, mean=0,sd=sd(samplemeans))*250,lwd=1)+ -->
<!--   geom_vline(aes(xintercept=0.7),lty="dashed",col="tomato1")+ -->
<!--   geom_vline(aes(xintercept=0),lty="dashed")+ -->
<!--   ylim(0,300)+ -->
<!--   labs(x = "mean stroop effect")+ -->
<!--   scale_y_continuous(NULL, breaks=NULL)+ -->
<!--   scale_x_continuous(NULL, breaks=NULL)+ -->
<!--   theme_minimal()+ -->
<!--   annotate("text",x=.3, y=125, label = expression(bar(x)-0), col="tomato1")+ -->
<!--   geom_segment(aes(x=0, xend=0.7, y=120, yend=120), col="tomato1", size=0.5, arrow = arrow(length = unit(0.03, "npc"),ends="both")) +  -->
<!--   geom_segment(aes(x=0, xend=sd(samplemeans), y=20, yend=20), col="tomato1", size=0.5)+ -->
<!--   annotate("text",x=1.12, y=50, label = expression(s/sqrt(n)), col="tomato1")+ -->
<!--   geom_curve(aes(x=1, xend=sd(samplemeans)-.1, y=50, yend=22), col="grey30", size=0.5, curvature = 0.2, arrow = arrow(length = unit(0.03, "npc"))) -->
<!-- ``` -->
</div>
<div id="tests-have-assumptions" class="section level2">
<h2>Tests have assumptions</h2>
<p>Conducting hypothesis tests entails holding certain assumptions, for instance that the observed sample has been drawn at random from the population of interest.</p>
<p>For the test we just performed we also require the assumption that the data are drawn from a normally distributed population.
In order to assess whether we have any evidence to reject this assumption, we can plot the data:</p>
<pre class="r"><code>plot(density(stroopdata$stroop_effect))
qqnorm(stroopdata$stroop_effect)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-22"></span>
<img src="03_nhst_files/figure-html/unnamed-chunk-22-1.png" alt="Stroop effect data: Density curve (normality is when curve is bell-shaped and symmetric), and Quantile-Quantile plot (normality is when lines fall on a straight diagonal)" width="80%" />
<p class="caption">
Figure 4: Stroop effect data: Density curve (normality is when curve is bell-shaped and symmetric), and Quantile-Quantile plot (normality is when lines fall on a straight diagonal)
</p>
</div>
<p>And we can also perform a hypothesis test against the null hypothesis that the data is drawn from a normally distributed population. <strong>Note</strong> that if the <span class="math inline">\(p\)</span>-value of this test is below our specified <span class="math inline">\(\alpha\)</span>, we have evidence that this assumption is violated (because the null hypothesis is our assumption)</p>
<pre class="r"><code>shapiro.test(stroopdata$stroop_effect)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  stroopdata$stroop_effect
## W = 0.9897, p-value = 0.4417</code></pre>
<p>Because <span class="math inline">\(p\)</span>&gt;.05, we fail to reject the null hypothesis of the Shapiro-Wilk test that the sample came from a population that is normally distributed.</p>
<div class="int">
<p>Shapiro-Wilk test did not indicate violation of the assumption of normality (<span class="math inline">\(W\)</span>=0.99, <span class="math inline">\(p\)</span>=0.442).</p>
</div>
</div>
</div>
<div id="exercises-some-basic-tests" class="section level1">
<h1>Exercises: Some basic tests</h1>
<div id="single-sample-t-test" class="section level2">
<h2>Single Sample <span class="math inline">\(t\)</span>-test</h2>
<div class="frame">
<blockquote>
<p><strong>Research Question</strong>
Do Edinburgh University students report endorsing procrastination less than the norm?</p>
</blockquote>
<p>The Procrastination Assessment Scale for Students (PASS) was designed to assess how individuals approach decision situations, specifically the tendency of individuals to postpone decisions (see <a href="http://dx.doi.org/10.1037/0022-0167.31.4.503">Solomon &amp; Rothblum, 1984</a>). The PASS assesses the prevalence of procrastination in six areas: writing a paper; studying for an exam; keeping up with reading; administrative tasks; attending meetings; and performing general tasks. For a measure of total endorsement of procrastination, responses to 18 questions (each measured on a 1-5 scale) are summed together, providing a single score for each participant (range 0 to 90). The mean score from Solomon &amp; Rothblum, 1984 was 33.</p>
<p>A student administers the PASS to 20 students from Edinburgh University.<br />
The data are available at <a href="https://uoepsy.github.io/data/pass_scores.csv" class="uri">https://uoepsy.github.io/data/pass_scores.csv</a>.</p>
</div>
<div class="question-begin">
Question A1
</div>
<div class="question-body">
<p>Conduct a one sample <span class="math inline">\(t\)</span>-test to evaluate whether Edinburgh University students’ average score on the PASS is less than 33. Remember to check the assumptions!</p>
<p><strong>Note:</strong> Think carefully about the wording of the research question. Is the alternative hypothesis “less than”, “greater than” or “not equal to”? What does this mean in relation to the areas of the <span class="math inline">\(t\)</span>-distribution for which you will reject the null hypothesis - upper tail, lower tail, or both tails? Check out the help page for <code>t.test()</code> - is there some thing you can change to make sure it is the correct option?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-39" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-39&#39;, &#39;sol-start-39&#39;)"></span>
</div>
<div id="sol-body-39" class="solution-body" style="display: none;">
<pre class="r"><code>pass_scores &lt;- read_csv(&quot;https://edin.ac/2wJgYwL&quot;) 

ggplot(data = pass_scores, aes(x=PASS)) + 
  geom_boxplot() + 
  geom_vline(xintercept=33, lty=&quot;dashed&quot;, col=&quot;red&quot;)</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-24-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>shapiro.test(pass_scores$PASS)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  pass_scores$PASS
## W = 0.93617, p-value = 0.2028</code></pre>
<pre class="r"><code>t.test(pass_scores$PASS, mu = 33, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  pass_scores$PASS
## t = -3.1073, df = 19, p-value = 0.0029
## alternative hypothesis: true mean is less than 33
## 95 percent confidence interval:
##     -Inf 31.9799
## sample estimates:
## mean of x 
##      30.7</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question A2
</div>
<div class="question-body">
<p>Write up the results.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-40" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-40&#39;, &#39;sol-start-40&#39;)"></span>
</div>
<div id="sol-body-40" class="solution-body" style="display: none;">
<div class="int">
<p>A one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of 20 students at Edinburgh University was significantly lower (<span class="math inline">\(\alpha = .05\)</span>) than the average score obtained during development of the PASS.</p>
<p>Edinburgh University students scored lower (Mean = 30.7, SD = 3.31) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant (t(19)=-3.11, p &lt; .05, one-tailed).</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="frame">
<blockquote>
<p><strong>Research Question</strong>
average height of students taking the statistics courses in Psychology at Edinburgh University in 2020/2021 is different from 165cm?</p>
</blockquote>
<p><img src="images/hypothesis/playmo_tms.jpg" width="30%" style="display: block; margin: auto;" /></p>
<p>The data for students from all psychology statistics courses are available at <a href="https://uoepsy.github.io/data/surveydata_allcourse.csv" class="uri">https://uoepsy.github.io/data/surveydata_allcourse.csv</a>.</p>
</div>
<div class="question-begin">
Question A3
</div>
<div class="question-body">
<p>Conduct a one sample <span class="math inline">\(t\)</span>-test to evaluate whether the average height of students taking the statistics courses in Psychology at Edinburgh University in 2020/2021 is different from 165cm.</p>
<p><strong>Remember:</strong> You should check that the data meet the assumptions of your test. This means you should investigate the extent to which your sample data appears to have been drawn from a normal distribution. However, <em>this is real data</em>, and <a href="https://dpananos.github.io/posts/2019/08/blog-post-23/">real data is rarely normal</a>! If you conduct a Shapiro-Wilk test, you may well find <span class="math inline">\(p&lt;.05\)</span> and conclude that your data is not normal.<br />
So what do we do if a test indicates our assumptions are violated?<br />
Well, we should bear a couple of things in mind.</p>
<ol style="list-style-type: decimal">
<li>A decision rule such as <span class="math inline">\(p&lt;.05\)</span> on Shapiro-Wilk test creates very dichotomous thinking for something which is in reality not black and white. Real life distributions are not <em>either</em> normal <em>or</em> non-normal. Plot the data, and make a judgement!<br />
</li>
<li>As it happens, the t-test is actually reasonably robust against slight deviations from normality! Plot your data and make a judgement!</li>
<li>The deeper you get into statistics, the more you discover that it is not simply a case of following step-by-step rules:
<img src="images/hypothesis/guidelines.gif" width="80%" style="display: block; margin: auto;" /></li>
</ol>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-41" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-41&#39;, &#39;sol-start-41&#39;)"></span>
</div>
<div id="sol-body-41" class="solution-body" style="display: none;">
<pre class="r"><code>survey_data &lt;- read_csv(&quot;https://uoepsy.github.io/data/surveydata_allcourse.csv&quot;)

#the shapiro.test suggests that our assumption of normality may be violated!! oh no!
shapiro.test(survey_data$height)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  survey_data$height
## W = 0.98905, p-value = 0.02641</code></pre>
<pre class="r"><code># However, let&#39;s have a histogram to check how non-normal our data is. 
# let&#39;s also add our hypothesised mean on there as a vertical line:
ggplot(data = survey_data, aes(x = height)) + 
  geom_histogram(bins=15) +
  geom_vline(xintercept = 165)</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-28-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># The t.test is quite robust against slight violations of normality.
# Our data here doesn&#39;t look too non-normal (This is just a judgement call here!).
# Let&#39;s proceed with the t.test
t.test(survey_data$height, mu = 165, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  survey_data$height
## t = 6.1309, df = 292, p-value = 2.829e-09
## alternative hypothesis: true mean is not equal to 165
## 95 percent confidence interval:
##  166.9993 168.8898
## sample estimates:
## mean of x 
##  167.9446</code></pre>
</div>
<p class="solution-end">
</p>
</div>
<div id="independent-samples-t-test" class="section level2">
<h2>Independent Samples <span class="math inline">\(t\)</span>-test</h2>
<p>In addition to testing the difference from an observed sample mean to some hypothesised mean, we can also conduct a <span class="math inline">\(t\)</span>-test to explore the difference between two observed sample means.</p>
<div class="frame">
<blockquote>
<p><strong>Research Question</strong>
Can a server earn higher tips simply by introducing themselves by name when greeting customers?</p>
</blockquote>
<p>Researchers investigated the effect of a server introducing herself by name on restaurant tipping.
The study involved forty, 2-person parties eating a $23.21 fixed-price buffet Sunday brunch at Charley Brown’s Restaurant in Huntington Beach, California, on April 10 and 17, 1988.
Each two-person party was randomly assigned by the waitress to either a name or a no name introduction condition using a random mechanism. The waitress kept track of the two-person party condition and how much the party paid at the end of the meal.</p>
<p>The data are available at <a href="https://uoepsy.github.io/data/gerritysim.csv" class="uri">https://uoepsy.github.io/data/gerritysim.csv</a>.<br />
(This is a simulated example based on <a href="https://doi.org/10.1111/j.1559-1816.1990.tb00405.x">Garrity and Degelman (1990)</a>)</p>
</div>
<div class="question-begin">
Question B1
</div>
<div class="question-body">
<p>Conduct an independent samples <span class="math inline">\(t\)</span>-test to assess whether higher tips are earned when the server introduces themselves by name, in comparison to when they do not.</p>
<p>Notes about assumptions</p>
<ul>
<li>Do the sample data arise from independent random samples from two populations OR from random assignment of the units to treatment groups?</li>
<li>Is the quantitative variable of interest normally distributed in <em>both</em> populations/groups?<br />
</li>
<li>Does the quantitative variable of interest have equal variance between the populations/groups? (you can test this using <code>var.test()</code>).</li>
</ul>
<div class="optional-begin">
Help: What do I need give the t.test() function?<span id="opt-start-42" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-42&#39;, &#39;opt-start-42&#39;)"></span>
</div>
<div id="opt-body-42" class="optional-body" style="display: none;">
<p>We can give <code>t.test()</code> two numeric vectors: <code>t.test(x = , y = )</code>.<br />
However, data can be stored in various different shapes.</p>
<p>If our data is <strong>wide</strong>:</p>
<pre><code>## # A tibble: 4 x 2
##   groupA groupB
##   &lt;chr&gt;  &lt;chr&gt; 
## 1 value  value 
## 2 value  value 
## 3 ...    ...   
## 4 ...    ...</code></pre>
<p>We can simply give <code>t.test()</code> both variables:</p>
<pre class="r"><code>t.test(x = data$groupA, y = data$groupB)</code></pre>
<hr />
<p>If our data is <strong>long</strong>:</p>
<pre><code>## # A tibble: 10 x 2
##    values group
##    &lt;chr&gt;  &lt;chr&gt;
##  1 value  A    
##  2 value  A    
##  3 ...    ...  
##  4 ...    ...  
##  5 value  A    
##  6 value  B    
##  7 value  B    
##  8 ...    ...  
##  9 ...    ...  
## 10 value  B</code></pre>
<ol style="list-style-type: decimal">
<li><p>Index the correct values:</p>
<pre class="r"><code>t.test(x = data$value[data$group==&quot;A&quot;], y = data$value[data$group==&quot;B&quot;])</code></pre></li>
<li><p>Or use the <strong>formula</strong> notation, using <code>~</code> (the “tilde”).<br />
In R, you can interpret <code>y ~ x</code> as “y is modeled as a function of x”.<br />
By splitting the numeric values by the categories of the “group” variable, we can conduct a <span class="math inline">\(t\)</span>-test using:</p>
<pre class="r"><code>t.test(data$value ~ data$group)</code></pre>
<p>Or, even more handy, we can use <code>with()</code>:</p>
<pre class="r"><code>with(data, t.test(value ~ group))</code></pre></li>
</ol>
</div>
<p class="optional-end">
</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-43" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-43&#39;, &#39;sol-start-43&#39;)"></span>
</div>
<div id="sol-body-43" class="solution-body" style="display: none;">
<pre class="r"><code>tipdata &lt;- read_csv(&quot;https://uoepsy.github.io/data/gerritysim.csv&quot;)

#make a &quot;tip&quot; column, which is minus the meal amount
tipdata &lt;- 
  tipdata %&gt;% mutate(
    tip = paid - 23.21
  )

ggplot(data = tipdata, aes(x = tip, y = condition)) +
  geom_boxplot()</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-35-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><strong>check assumptions</strong></p>
<pre class="r"><code>shapiro.test(tipdata$tip[tipdata$condition==&quot;name&quot;])</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  tipdata$tip[tipdata$condition == &quot;name&quot;]
## W = 0.96267, p-value = 0.5985</code></pre>
<pre class="r"><code>shapiro.test(tipdata$tip[tipdata$condition==&quot;no name&quot;])</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  tipdata$tip[tipdata$condition == &quot;no name&quot;]
## W = 0.94405, p-value = 0.2857</code></pre>
<pre class="r"><code>with(tipdata, var.test(tip ~ condition))</code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  tip by condition
## F = 1.9344, num df = 19, denom df = 19, p-value = 0.1595
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.7656473 4.8870918
## sample estimates:
## ratio of variances 
##            1.93437</code></pre>
<p><strong>conduct t-test</strong></p>
<pre class="r"><code>with(tipdata, t.test(tip ~ condition, alternative = &quot;greater&quot;))</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  tip by condition
## t = 3.4117, df = 34.502, p-value = 0.0008314
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.8893105       Inf
## sample estimates:
##    mean in group name mean in group no name 
##                4.9450                3.1825</code></pre>
</div>
<p class="solution-end">
</p>
</div>
</div>
<div id="exercises-writing-results-in-rmarkdown" class="section level1">
<h1>Exercises: Writing results in Rmarkdown</h1>
<p>For the results of a <span class="math inline">\(t\)</span>-test, we can write our results like this:</p>
<div class="frame">
<p><img src="images/hypothesis/rmarkdownbacktick.png" width="1000px" style="display: block; margin: auto;" /></p>
</div>
<p>In order for them to be compiled like this:</p>
<div class="frame">
<p>A one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of 20 students at Edinburgh University was significantly lower (<span class="math inline">\(\alpha = .05\)</span>) than the average score obtained during development of the PASS.</p>
<p>Edinburgh University students scored lower (Mean = 30.7, SD = 3.31) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant (t(19)=-3.11, p &lt; .05, one-tailed).</p>
</div>
<p>This is one of the huge benefits of RMarkdown. Imagine we collected more data - we wouldn’t have to edit all the results, we could simply recompile and they would update for us!<br />
Note how it works:</p>
<ul>
<li>the code chunk saves the results of the <code>t.test()</code> function as a named object <code>res2</code>.</li>
<li>in text, the backticks <code>`r … … … `</code> are used to execute small bits of R code, and include the output within the text. For instance, the line <code>`r res2$statistic %&gt;% round(2)`</code> gets the t-statistic from the results, and rounds it to 2 decimal places, which get’s printed out as -3.11.</li>
</ul>
<div class="question-begin">
Question C1
</div>
<div class="question-body">
<p>Write up the results of from question B1 above, using as much inline R code (the backticks) as you can.</p>
<p>Compile your document to ensure that it gets rendered correctly.</p>
<p>No solution for this one I’m afraid.. It might be a bit of a trial-and-error to figure out why a document doesn’t compile. Try to read the errors - they (sometimes) give you clues.</p>
<p class="question-end">
</p>
</div>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>

<div>
  <hr/>
  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br/>
  This workbook was written by Josiah King, Umberto Noe, and Martin
  Corley, and is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
