<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Model Fit, Comparison, and Selection</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-plus')) {
    f.classList.add('fa-minus')
    f.classList.remove('fa-plus')
} else {
    f.classList.add('fa-plus')
    f.classList.remove('fa-minus')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>DAPR2</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fas fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Simple Linear Regression
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_models.html">1/1: Functions and models</a>
    </li>
    <li>
      <a href="02_slr.html">1/2: Simple linear regression</a>
    </li>
    <li>
      <a href="03_slr_model_fit.html">1/3: Model Fit, Standardized Coefficients</a>
    </li>
    <li>
      <a href="04_slr_assumptions.html">1/4: Assumptions &amp; Diagnostics</a>
    </li>
    <li>
      <a href="05_slr_writeup.html">1/5: Writing-up</a>
    </li>
    <li class="dropdown-header">1/6: Break week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Multiple Linear Regression
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06_mlr.html">1/7: Basics</a>
    </li>
    <li>
      <a href="07_mlr_int.html">1/8: Interactions</a>
    </li>
    <li>
      <a href="08_mlr_assumpt.html">1/9: Assumptions &amp; Diagnostics</a>
    </li>
    <li>
      <a href="09_mlr_select.html">1/10: Model Fit, Model Comparison, Model Selection</a>
    </li>
    <li>
      <a href="10_mlr_report.html">1/11: Writing-up</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Experimental Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="11_anova.html">2/1: ANOVA</a>
    </li>
    <li>
      <a href="11_anova.html">2/2: ANOVA (again)</a>
    </li>
    <li>
      <a href="12_factorial_anova.html">2/3: 2x2 ANOVA</a>
    </li>
    <li>
      <a href="13_multiplecomp.html">2/4: Multiple Comparisons</a>
    </li>
    <li class="dropdown-header">2/5: No exercises</li>
    <li class="dropdown-header">2/6: Break week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced Topics for LM
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="14_bootstrap_reg.html">2/7: Bootstrap</a>
    </li>
    <li>
      <a href="15_binary_logistic.html">2/8: Binary Logistic Regression</a>
    </li>
    <li>
      <a href="16_more_about_logistic.html">2/9: More About Logistic Regression</a>
    </li>
    <li>
      <a href="17_power_regression.html">2/10: Sample Size and Power Analysis</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Help
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="intro_r_rstudio.html">Getting started with R &amp; RStudio</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Model Fit, Comparison, and Selection</h1>

</div>


<div class="green">
<p>Be sure to check the <a href="08_mlr_assumpt.html"><strong>solutions to last week’s exercises</strong></a>.<br>You can still ask any questions about previous weeks’ materials if things aren’t clear!</p>
</div>
<div class="lo">
<p><strong>LEARNING OBJECTIVES</strong></p>
<ol style="list-style-type: decimal">
<li>Understand measures of model fit using <span class="math inline">\(R^2\)</span> and F.<br />
</li>
<li>Understand the principles of model selection and how to compare models via <span class="math inline">\(R^2\)</span> and F tests.</li>
<li>Understand AIC and BIC.</li>
<li>Understand the basics of backward elimination, forward selection and stepwise regression.</li>
</ol>
</div>
<div id="model-fit" class="section level1">
<h1>Model Fit</h1>
<div id="adjusted-r2" class="section level2 frame">
<h2>Adjusted <span class="math inline">\(R^2\)</span></h2>
<p>We know from our work on simple linear regression that the R-squared can be obtained as:
<span class="math display">\[
R^2 = \frac{SS_{Model}}{SS_{Total}} = 1 - \frac{SS_{Residual}}{SS_{Total}}
\]</span></p>
<p>However, when we add more and more predictors into a multiple regression model, <span class="math inline">\(SS_{Residual}\)</span> cannot increase, and may decrease by pure chance alone, even if the predictors are unrelated to the outcome variable. Because <span class="math inline">\(SS_{Total}\)</span> is constant, the calculation <span class="math inline">\(1-\frac{SS_{Residual}}{SS_{Total}}\)</span> will increase by chance alone.</p>
<p>An alternative, the Adjusted-<span class="math inline">\(R^2\)</span>, does not necessarily increase with the addition of more explanatory variables, by including a penalty according to the number of explanatory variables in the model. It is not by itself meaningful, but can be useful in determining what predictors to include in a model.
<span class="math display">\[
Adjusted{-}R^2=1-\frac{(1-R^2)(n-1)}{n-k-1} \\
\quad \\
\begin{align}
&amp; \text{Where:} \\
&amp; n = \text{sample size} \\
&amp; k = \text{number of explanatory variables} \\
\end{align}
\]</span></p>
<hr />
<p><strong>In R,</strong> you can view the mutiple and adjusted <span class="math inline">\(R^2\)</span> at the bottom of the output of <code>summary(&lt;modelname&gt;)</code>:</p>
<div class="figure" style="text-align: left"><span id="fig:mlroutputrsq"></span>
<img src="images/mlroutputrsq.png" alt="Multiple regression output in R, summary.lm(). R-squared highlighted" width="60%" />
<p class="caption">
Figure 1: Multiple regression output in R, summary.lm(). R-squared highlighted
</p>
</div>
</div>
<div id="f-ratio" class="section level2 frame">
<h2>F-ratio</h2>
<p>As in simple linear regression, the F-ratio is used to test the null hypothesis that all regression slopes are zero.</p>
<p>It is called the F-ratio because it is the ratio of the how much of the variation is explained by the model (per paramater) versus how much of the variation is unexplained (per remaining degrees of freedom).</p>
<p><span class="math display">\[
F_{df_{model},df_{residual}} = \frac{MS_{Model}}{MS_{Residual}} = \frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\
\quad \\
\begin{align}
&amp; \text{Where:} \\
&amp; df_{model} = k \\
&amp; df_{error} = n-k-1 \\
&amp; n = \text{sample size} \\
&amp; k  = \text{number of explanatory variables} \\
\end{align}
\]</span></p>
<hr />
<p><strong>In R,</strong> at the bottom of the output of <code>summary(&lt;modelname&gt;)</code>, you can view the F ratio, along with an hypothesis test against the alternative hypothesis that the at least one of the coefficients <span class="math inline">\(\neq 0\)</span> (under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1):</p>
<div class="figure" style="text-align: left"><span id="fig:mlroutputrf"></span>
<img src="images/mlroutputf.png" alt="Multiple regression output in R, summary.lm(). F statistic highlighted" width="60%" />
<p class="caption">
Figure 2: Multiple regression output in R, summary.lm(). F statistic highlighted
</p>
</div>
</div>
<div class="question-begin">
Question 1
</div>
<div class="question-body">
<p>Run the code below. It reads in the wellbeing/rurality study data, and creates a new binary variable which specifies whether or not each participant lives in a rural location.</p>
<pre class="r"><code>library(tidyverse)
mwdata2&lt;-read_csv(&quot;https://uoepsy.github.io/data/wellbeing_rural.csv&quot;)
mwdata2 &lt;- 
  mwdata2 %&gt;% mutate(
  isRural = ifelse(location==&quot;rural&quot;,&quot;rural&quot;,&quot;notrural&quot;)
)</code></pre>
<p>Fit the following model, and assign it the name “wb_mdl1.”</p>
<ul>
<li><span class="math inline">\(\text{Wellbeing} = \beta_0 + \beta_1 \cdot \text{Social Interactions} + \beta_2 \cdot \text{IsRural} + \epsilon\)</span></li>
</ul>
<p>Does the model provide a better fit to the data than a model with no explanatory variables? (i.e., test against the alternative hypothesis that at least one of the explanatory variables significantly predicts wellbeing scores).</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-116" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-116&#39;, &#39;sol-start-116&#39;)"></span>
</div>
<div id="sol-body-116" class="solution-body" style="display: none;">
<pre class="r"><code>wb_mdl1 &lt;- lm(wellbeing ~ social_int + isRural, data=mwdata2)
summary(wb_mdl1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wellbeing ~ social_int + isRural, data = mwdata2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.3711  -3.1794   0.1097   2.5407  17.6324 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  34.11591    1.07052  31.868  &lt; 2e-16 ***
## social_int    0.38167    0.08257   4.622 6.85e-06 ***
## isRuralrural -4.85152    0.66283  -7.319 6.18e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.664 on 197 degrees of freedom
## Multiple R-squared:  0.2593, Adjusted R-squared:  0.2517 
## F-statistic: 34.47 on 2 and 197 DF,  p-value: 1.453e-13</code></pre>
<div class="int">
<p>Weekly social interactions and location (rural vs not rural) explained 25.2% of the variance (adjusted <span class="math inline">\(R^2\)</span> =0.252, <span class="math inline">\(F\)</span>(2,197)=34.5, p&lt;.001)</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="model-comparison" class="section level1">
<h1>Model Comparison</h1>
<div id="incremental-f-test" class="section level2 frame">
<h2>Incremental F-test</h2>
<div class="yellow">
<p>If (<em>and only if</em>) two models are <strong>nested</strong> (one model contains all the predictors of the other and is fitted to the same data), we can compare them using an <strong>incremental F-test.</strong></p>
<p>This is a formal test of whether the additional predictors provide a better fitting model.<br />
Formally this is the test of:</p>
<ul>
<li><span class="math inline">\(H_0:\)</span> coefficients for the added/ommitted variables are all zero.</li>
<li><span class="math inline">\(H_1:\)</span> at least one of the added/ommitted variables has a coefficient that is not zero.</li>
</ul>
</div>
<p>The F-ratio for comparing the residual sums of squares between two models can be calculated as:</p>
<p><span class="math display">\[
F_{(df_R-df_F),df_F} = \frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\
\quad \\
\begin{align}
&amp; \text{Where:} \\
&amp; SSR_R = \text{residual sums of squares for the restricted model} \\
&amp; SSR_F = \text{residual sums of squares for the full model} \\
&amp; df_R = \text{residual degrees of freedom from the restricted model} \\
&amp; df_F = \text{residual degrees of freedom from the full model} \\
\end{align}
\]</span></p>
<hr />
<p><strong>In R,</strong> we can conduct an incremental F-test by constructing two models, and passing them to the <code>anova()</code> function: <code>anova(model1, model2)</code>.</p>
</div>
<div class="question-begin">
Question 2
</div>
<div class="question-body">
<p>The F-ratio you see at the bottom of <code>summary(model)</code> is actually a comparison between two models: your model (with some explanatory variables in predicting <span class="math inline">\(y\)</span>) and <strong>the null model.</strong> In regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the <strong>intercept-only model</strong>, because if all predictor variable coefficients are zero, then the only we are only estimating <span class="math inline">\(y\)</span> via an intercept (which will be the mean - <span class="math inline">\(\bar y\)</span>).</p>
<p>Use the code below to fit the null model.<br />
Then, use the <code>anova()</code> function to perform a model comparison between your earlier model (<strong>wb_mdl1</strong>) and the null model.<br />
Check that the F statistic is the same as that which is given at the bottom of <code>summary(wb_mdl1)</code>.</p>
<pre class="r"><code>null_model &lt;- lm(wellbeing ~ 1, data = mwdata2)</code></pre>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-117" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-117&#39;, &#39;sol-start-117&#39;)"></span>
</div>
<div id="sol-body-117" class="solution-body" style="display: none;">
<pre class="r"><code># fit the null model
null_model &lt;- lm(wellbeing ~ 1, data = mwdata2)

# model comparison null vs wb_mdl1
anova(null_model, wb_mdl1)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wellbeing ~ 1
## Model 2: wellbeing ~ social_int + isRural
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    199 5785.6                                  
## 2    197 4285.6  2      1500 34.475 1.453e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># extract f statistic from summary of wb_mdl1
summary(wb_mdl1)$fstatistic</code></pre>
<pre><code>##     value     numdf     dendf 
##  34.47463   2.00000 197.00000</code></pre>
<pre class="r"><code># we can retrieve the p-value:
fstat = summary(wb_mdl1)$fstatistic[1]
df_1 = summary(wb_mdl1)$fstatistic[2]
df_2 = summary(wb_mdl1)$fstatistic[3]
pf(fstat, df_1, df_2, lower.tail = FALSE)</code></pre>
<pre><code>##        value 
## 1.452925e-13</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 3
</div>
<div class="question-body">
<p>Does weekly outdoor time explain a significant amount of variance in wellbeing scores over and above weekly social interactions and location (rural vs not-rural)?</p>
<p>Provide an answer to this question by fitting and comparing two models (one of them you may already have fitted in an earlier question).</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-118" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-118&#39;, &#39;sol-start-118&#39;)"></span>
</div>
<div id="sol-body-118" class="solution-body" style="display: none;">
<p>We can compare the following models which predict wellbeing scores from weekly social interactions and location, with and without weekly outdoor time.</p>
<ul>
<li><span class="math inline">\(\text{Wellbeing} = \beta_0 + \beta_1 \cdot \text{Social Interactions} + \beta_2 \cdot \text{IsRural} + \epsilon\)</span></li>
<li><span class="math inline">\(\text{Wellbeing} = \beta_0 + \beta_1 \cdot \text{Social Interactions} + \beta_2 \cdot \text{IsRural} + \beta_3 \cdot \text{Outdoor time} + \epsilon\)</span></li>
</ul>
<p>We have already fitted the first model and assigned it the name <code>wb_mdl1</code>.<br />
We need to fit the second:</p>
<pre class="r"><code>wb_mdl2 &lt;- lm(wellbeing ~ 1 + social_int + isRural + outdoor_time, data=mwdata2)</code></pre>
<p>Let’s look at the amount of variation in wellbeing scores explained by each model:</p>
<pre class="r"><code>summary(wb_mdl1)$adj.r.squared</code></pre>
<pre><code>## [1] 0.251737</code></pre>
<pre class="r"><code>summary(wb_mdl2)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3037301</code></pre>
<p>The model <em>with</em> weekly outdoor time as a predictor explains 30% of the variance, and the model <em>without</em> explains 25%.<br />
Does including weekly outdoor time as a predictor provide a significantly better fit of the data (<strong>wb_mdl2</strong> compared to <strong>wb_mdl1</strong>)?</p>
<pre class="r"><code>anova(wb_mdl1, wb_mdl2)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wellbeing ~ social_int + isRural
## Model 2: wellbeing ~ 1 + social_int + isRural + outdoor_time
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    197 4285.6                                  
## 2    196 3967.6  1    318.03 15.711 0.0001033 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="int">
<p>Weekly outdoor time was found to explain a significant amount of variance in wellbeing scores over and above weekly social interactions and location (rural vs not-rural)<br />
<span class="math inline">\(F\)</span>(1 )=NA, 15.71, p&lt;.001.</p>
</div>
</div>
<p class="solution-end">
</p>
<div id="incremental-validity---a-caution" class="section level2 frame">
<h2>Incremental validity - A caution</h2>
<p>A common goal for researchers is to determine which variables matter (and which do not) in contributing to some outcome variable. A common approach to answer such questions is to consider whether some variable <span class="math inline">\(X\)</span>’s contribution remains significant <em>after</em> controlling for variables <span class="math inline">\(Z\)</span>.</p>
<p>The reasoning:</p>
<ul>
<li>If our measure of <span class="math inline">\(X\)</span> correlates significantly with outcome <span class="math inline">\(Y\)</span> even when controlling for our measure of <span class="math inline">\(Z\)</span>, then <span class="math inline">\(X\)</span> contributes to <span class="math inline">\(y\)</span> <em>over and above</em> the contribution of <span class="math inline">\(Z\)</span>.</li>
</ul>
<p>In multiple regression, we might fit the model <span class="math inline">\(Y = \beta_0 + \beta_1 \cdot X + \beta_2 \cdot Z + \epsilon\)</span> and conclude that <span class="math inline">\(X\)</span> is a useful predictor of <span class="math inline">\(Y\)</span> <em>over and above</em> <span class="math inline">\(Z\)</span> based on the estimate <span class="math inline">\(\hat \beta_1\)</span>, or via model comparison between that model and the model without <span class="math inline">\(Z\)</span> as a predictor (<span class="math inline">\(Y = \beta_0 + \beta_1 \cdot X + \epsilon\)</span>).</p>
<p><strong>A Toy Example</strong></p>
<p>Suppose we have monthly data over a seven year period which captures the number of shark attacks on swimmers each month, and the number of ice-creams sold by beach vendors each month.<br />
Consider the relationship between the two:<br />
<img src="09_mlr_select_files/figure-html/unnamed-chunk-10-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>We can fit the linear model and see a significant relationship between ice cream sales and shark attacks:</p>
<pre class="r"><code>sharkdata &lt;- read_csv(&quot;https://uoepsy.github.io/data/sharks.csv&quot;)
shark_mdl &lt;- lm(shark_attacks ~ ice_cream_sales, data = sharkdata)
summary(shark_mdl)</code></pre>
<pre><code>## 
## Call:
## lm(formula = shark_attacks ~ ice_cream_sales, data = sharkdata)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.3945  -4.9268   0.5087   4.8152  15.7023 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      5.58835    5.19063   1.077    0.285    
## ice_cream_sales  0.32258    0.05809   5.553 3.46e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.245 on 81 degrees of freedom
## Multiple R-squared:  0.2757, Adjusted R-squared:  0.2668 
## F-statistic: 30.84 on 1 and 81 DF,  p-value: 3.461e-07</code></pre>
<div class="question-begin">
Question
</div>
<div class="question-body">
<p>Does the relationship between ice cream sales and shark attacks make sense? What might be missing from our model?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution
</div>
<div class="solution-body">
<p>You might quite rightly suggest that this relationship is actually being driven by temperature - when it is hotter, there are more ice cream sales <em>and</em> there are more people swimming (hence more shark attacks).</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question
</div>
<div class="question-body">
<p>Is <span class="math inline">\(X\)</span> (the number of ice-cream sales) a useful predictor of <span class="math inline">\(Y\)</span> (numbers of shark attacks) over and above <span class="math inline">\(Z\)</span> (temperature)?<br />
<br>
We might answer this with a multiple regression model including both temperature and ice cream sales as predictors of shark attacks:</p>
<pre class="r"><code>shark_mdl2 &lt;- lm(shark_attacks ~ ice_cream_sales + temperature, data = sharkdata)
summary(shark_mdl2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = shark_attacks ~ ice_cream_sales + temperature, data = sharkdata)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.5359  -3.1353   0.1088   3.1064  17.2566 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      1.73422    4.27917   0.405    0.686    
## ice_cream_sales  0.08588    0.05997   1.432    0.156    
## temperature      1.31868    0.20457   6.446 8.04e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.914 on 80 degrees of freedom
## Multiple R-squared:  0.5233, Adjusted R-squared:  0.5114 
## F-statistic: 43.91 on 2 and 80 DF,  p-value: 1.345e-13</code></pre>
<p><br>
What do you conclude?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution
</div>
<div class="solution-body">
<p>It appears that numbers of ice cream sales is <em>not</em> a significant predictor of sharks attack numbers over and above the temperature.</p>
</div>
<p class="solution-end">
</p>
<p><strong>However…</strong>
In psychology, we can rarely observe and directly measure the constructs which we are interested in (for example, personality traits, intelligence, emotional states etc.). We rely instead on measurements of, e.g. behavioural tendencies, as a proxy for personality traits.</p>
<p>Let’s suppose that instead of including temperature in degrees celsius, we asked a set of people to self-report on a scale of 1 to 7 how hot it was that day. This measure should hopefully correlate well with the <em>actual</em> temperature, however, there will likely be some variation:
<img src="09_mlr_select_files/figure-html/unnamed-chunk-13-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="question-begin">
Question
</div>
<div class="question-body">
<p>Is <span class="math inline">\(X\)</span> (the number of ice-cream sales) a useful predictor of <span class="math inline">\(Y\)</span> (numbers of shark attacks) over and above <span class="math inline">\(Z\)</span> (temperature - measured on our self-reported heat scale)?<br />
<br></p>
<pre class="r"><code>shark_mdl2a &lt;- lm(shark_attacks ~ ice_cream_sales + sr_heat, data = sharkdata)
summary(shark_mdl2a)</code></pre>
<pre><code>## 
## Call:
## lm(formula = shark_attacks ~ ice_cream_sales + sr_heat, data = sharkdata)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4576  -3.7818  -0.0553   3.6712  15.2155 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      8.96066    4.37145   2.050  0.04366 *  
## ice_cream_sales  0.14943    0.05643   2.648  0.00974 ** 
## sr_heat          2.96130    0.49276   6.010 5.24e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.051 on 80 degrees of freedom
## Multiple R-squared:  0.501,  Adjusted R-squared:  0.4885 
## F-statistic: 40.16 on 2 and 80 DF,  p-value: 8.394e-13</code></pre>
<p><br>
What do you conclude?</p>
<p class="question-end">
</p>
</div>
<p>Moral of the story: be considerate of what exactly it is that you are measuring.
<br>
This example was adapted from <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/pere.12309">Westfall and Yarkoni, 2020</a> which provides a much more extensive discussion of incremental validity and type 1 error rates.</p>
</div>
<div id="aic-bic" class="section level2 frame">
<h2>AIC &amp; BIC</h2>
<p>We can also compare models using information criterion statistics, such as AIC and BIC. These combine information about the sample size, the number of model parameters and the residual sums of squares (<span class="math inline">\(SS_{residual}\)</span>). Models do not need to be nested to be compared via AIC and BIC, but they need to have been fit to the same dataset.<br />
For both of these fit indices, lower values are better, and both include a penalty for the number of predictors in the model, although BIC’s penalty is harsher:</p>
<p><span class="math display">\[
AIC = n\,\text{ln}\left( \frac{SS_{residual}}{n} \right) + 2k \\
\quad \\
BIC = n\,\text{ln}\left( \frac{SS_{residual}}{n} \right) + k\,\text{ln}(n) \\
\quad \\
\begin{align}
&amp; \text{Where:} \\
&amp; SS_{residual} = \text{sum of squares residuals} \\
&amp; n = \text{sample size} \\
&amp; k = \text{number of explanatory variables} \\
&amp; \text{ln} = \text{natural log function} 
\end{align}
\]</span></p>
<hr />
<p><strong>In R,</strong> we can calculate AIC and BIC by using the <code>AIC()</code> and <code>BIC()</code> functions.</p>
</div>
<div class="question-begin">
Question 4
</div>
<div class="question-body">
<p>The code below fits 5 different models:</p>
<pre class="r"><code>model1 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata2)
model2 &lt;- lm(wellbeing ~ social_int + outdoor_time + age, data = mwdata2)
model3 &lt;- lm(wellbeing ~ social_int + outdoor_time + routine, data = mwdata2)
model4 &lt;- lm(wellbeing ~ social_int + outdoor_time + routine + age, data = mwdata2)
model5 &lt;- lm(wellbeing ~ social_int + outdoor_time + routine + steps_k, data = mwdata2)</code></pre>
<p>For each of the below pairs of models, what methods are/are not available for us to use for comparison and why?</p>
<ul>
<li><code>model1</code> vs <code>model2</code></li>
<li><code>model2</code> vs <code>model3</code></li>
<li><code>model1</code> vs <code>model4</code></li>
<li><code>model3</code> vs <code>model5</code></li>
</ul>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-121" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-121&#39;, &#39;sol-start-121&#39;)"></span>
</div>
<div id="sol-body-121" class="solution-body" style="display: none;">
<ul>
<li><p><code>model1</code> vs <code>model2</code><br />
These models are nested - <code>model2</code> contains all the variables of <code>model1</code> and they are fitted on the same dataset.<br />
We can therefore use an F-test, AIC or BIC.</p></li>
<li><p><code>model2</code> vs <code>model3</code><br />
These models are <strong>not</strong> nested, but they are fitted on the same dataset.<br />
We can therefore use AIC or BIC, but we cannot use an F-test.</p></li>
<li><p><code>model1</code> vs <code>model4</code>
These models are nested - <code>model4</code> contains all the variables of <code>model1</code> and they are fitted on the same dataset.<br />
We can therefore use an F-test, AIC or BIC.</p></li>
<li><p><code>model3</code> vs <code>model5</code><br />
These models are <strong>not</strong> nested, and they are <strong>not</strong> fitted on the same dataset. the “steps_k” variable contains missing values, and so these whole rows are excluded from <code>model5</code> (but they are included in <code>model3</code>). We cannot compare these models.</p></li>
</ul>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 5
</div>
<div class="question-body">
<p>Recall the data on Big 5 Personality traits, perceptions of social ranks, and depression and anxiety scale scores:</p>
<pre class="r"><code>scs_study &lt;- read_csv(&quot;https://uoepsy.github.io/data/scs_study.csv&quot;)
summary(scs_study)</code></pre>
<pre><code>##        zo                 zc                 ze                 za          
##  Min.   :-2.81928   Min.   :-3.21819   Min.   :-3.00576   Min.   :-2.94429  
##  1st Qu.:-0.63089   1st Qu.:-0.66866   1st Qu.:-0.68895   1st Qu.:-0.69394  
##  Median : 0.08053   Median : 0.00257   Median :-0.04014   Median :-0.01854  
##  Mean   : 0.09202   Mean   : 0.01951   Mean   : 0.00000   Mean   : 0.00000  
##  3rd Qu.: 0.80823   3rd Qu.: 0.71215   3rd Qu.: 0.67085   3rd Qu.: 0.72762  
##  Max.   : 3.55034   Max.   : 3.08015   Max.   : 2.80010   Max.   : 2.97010  
##        zn               scs             dass      
##  Min.   :-1.4486   Min.   :27.00   Min.   :23.00  
##  1st Qu.:-0.7994   1st Qu.:33.00   1st Qu.:41.00  
##  Median :-0.2059   Median :35.00   Median :44.00  
##  Mean   : 0.0000   Mean   :35.77   Mean   :44.72  
##  3rd Qu.: 0.5903   3rd Qu.:38.00   3rd Qu.:49.00  
##  Max.   : 3.3491   Max.   :54.00   Max.   :68.00</code></pre>
<blockquote>
<p><strong>Research question</strong></p>
<ul>
<li>Beyond neuroticism and its interaction with social comparison, do other personality traits predict symptoms of depression, anxiety and stress?</li>
</ul>
</blockquote>
<p>Construct and compare multiple regression models to answer this question. Remember to check that your models meet assumptions (for this exercises, a quick eyeball of the diagnostic plots will suffice. Were this an actual research project, you would want to provide a more thorough check, for instance conducting formal tests of the assumptions).<br />
<br>
Although the solutions are available immediately for this question, we strongly advocate that you attempt it yourself before looking at them.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-122" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-122&#39;, &#39;sol-start-122&#39;)"></span>
</div>
<div id="sol-body-122" class="solution-body" style="display: none;">
<p>First let us mean-center our social comparison scale scores, as we did in the previous labs.</p>
<pre class="r"><code>scs_study &lt;- 
  scs_study %&gt;%
  mutate(
    scs_mc = scs - mean(scs)
  )</code></pre>
<p>The question is asking whether including a group of predictors (the O, C, E, A personality traits) improves model fit beyond a model with just neuoriticism, social comparison score and their interaction.</p>
<p>Notice how our initial model has one very influential point, which we will remove:</p>
<pre class="r"><code>dass_mod &lt;- lm(dass ~ scs_mc * zn, data = scs_study)
plot(dass_mod)</code></pre>
<p><img src="09_mlr_select_files/figure-html/unnamed-chunk-20-1.png" width="60%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>dass_mod &lt;- lm(dass ~ scs_mc * zn, data = scs_study[-35, ])
plot(dass_mod)</code></pre>
<p><img src="09_mlr_select_files/figure-html/unnamed-chunk-22-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>And our full model, with the other personality variables included:</p>
<pre class="r"><code>dass_mod2 &lt;- lm(dass ~ scs_mc * zn + zo + zc + ze + za, data = scs_study[-35, ])
plot(dass_mod2)</code></pre>
<p><img src="09_mlr_select_files/figure-html/unnamed-chunk-24-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>We can explore the individual coefficients of our full model, and we notice that none of the other personality variables (<code>zo</code>, <code>zc</code>, <code>ze</code>, <code>za</code>) significantly predict DASS-21 scores:</p>
<pre class="r"><code>summary(dass_mod2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dass ~ scs_mc * zn + zo + zc + ze + za, data = scs_study[-35, 
##     ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.1455  -3.8155  -0.0066   3.6905  18.1483 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 44.97703    0.22635 198.708  &lt; 2e-16 ***
## scs_mc      -0.54832    0.06519  -8.412 2.58e-16 ***
## zn           1.41639    0.22661   6.250 7.44e-10 ***
## zo          -0.31435    0.22056  -1.425    0.155    
## zc           0.09134    0.22515   0.406    0.685    
## ze           0.52695    0.34233   1.539    0.124    
## za           0.33847    0.34281   0.987    0.324    
## scs_mc:zn   -0.78254    0.06817 -11.479  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.733 on 647 degrees of freedom
## Multiple R-squared:  0.279,  Adjusted R-squared:  0.2712 
## F-statistic: 35.76 on 7 and 647 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>However, when we compare the two models, we find that including these predictors does significantly improve model fit.</p>
<pre class="r"><code>anova(dass_mod, dass_mod2)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: dass ~ scs_mc * zn
## Model 2: dass ~ scs_mc * zn + zo + zc + ze + za
##   Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)   
## 1    651 21763                              
## 2    647 21262  4    501.25 3.8133 0.0045 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This may be a bit confusing - are we saying that none of openness, conscientiousness, agreeableness, or extraversion significantly predict DASS-21 scores, but collectively they do?</p>
<p>This sort of discrepancy can often be the result of multicollinearity. Note that there may be some correlation between the <code>za</code> and <code>ze</code> variables:</p>
<pre class="r"><code>library(car)
vif(dass_mod2)</code></pre>
<pre><code>##    scs_mc        zn        zo        zc        ze        za scs_mc:zn 
##  1.015133  1.015736  1.013310  1.008235  2.332486  2.342220  1.012475</code></pre>
<p>What may actually be happening here is that one variable is <em>masking</em> the effect of the other. Note that when we take one of them out, the other becomes significant:</p>
<pre class="r"><code>lm(dass ~ scs_mc * zn + zo + zc + ze, data = scs_study[-35, ]) %&gt;% summary</code></pre>
<pre><code>## 
## Call:
## lm(formula = dass ~ scs_mc * zn + zo + zc + ze, data = scs_study[-35, 
##     ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.1327  -3.8012  -0.0145   3.7151  17.8952 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 44.97614    0.22634 198.709  &lt; 2e-16 ***
## scs_mc      -0.55175    0.06509  -8.476  &lt; 2e-16 ***
## zn           1.42834    0.22629   6.312 5.11e-10 ***
## zo          -0.30725    0.22044  -1.394 0.163853    
## zc           0.10062    0.22495   0.447 0.654794    
## ze           0.78223    0.22437   3.486 0.000523 ***
## scs_mc:zn   -0.78132    0.06816 -11.463  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.732 on 648 degrees of freedom
## Multiple R-squared:  0.2779, Adjusted R-squared:  0.2712 
## F-statistic: 41.56 on 6 and 648 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p class="solution-end">
</p>
</div>
<div id="extra-exercises-model-selection" class="section level1">
<h1>Extra Exercises: Model Selection</h1>
<p><strong>“Which predictors should I include in my model?”</strong></p>
<p>As a rule of thumb, you should include as predictors your variables of interest (i.e., those required to answer your questions), and those which theory suggests you should take into account (for instance, if theory tells you that temperature is likely to influence the number of shark attacks on a given day, it would be remiss of you to not include it in your model).</p>
<p>However, in some specific situations, you may simply want to let the data tell you whatever there is to tell, without being guided by theory. This is where analysis becomes <strong>exploratory</strong> in nature (and therefore should <em>not</em> be used as confirmatory evidence in support of theory).</p>
<p>In both the design and the analysis of a study, you will have to make many many choices. Each one takes you a different way, and leads to a different set of choices. This idea has become widely known as the <a href="https://www.americanscientist.org/article/the-statistical-crisis-in-science">garden of forking paths</a>, and has important consequences for your statistical inferences.</p>
<p>Out of all the possible paths you could have taken, some will end with what you consider to be a significant finding, and some you will simply see as dead ends. If you reach a dead-end, do you go back and try a different path? Why might this be a risky approach to statistical analyses?</p>
<p>For a given set of data, there will likely be some significant relationships between variables which are there simply by chance (recall that <span class="math inline">\(p&lt;.05\)</span> corresponds to a 1 in 20 chance - if we study 20 different relationships, we would expect one of them two be significant by chance). The more paths we try out, the more likely we are to find a significant relationship, even though it may actually be completely spurious!</p>
<p>Model selection is a means of answering the question “which predictors should I include in my model?” but it is a big maze of forking paths, which will result in keeping only those predictors which meet some criteria (e.g., significance).</p>
<div id="stepwise" class="section level2 frame">
<h2>Stepwise</h2>
<p><strong>Forward Selection</strong></p>
<ul>
<li>Start with variable which has highest association with DV.</li>
<li>Add the variable which most increases <span class="math inline">\(R^2\)</span> out of all which remain.</li>
<li>Continue until no variables improve <span class="math inline">\(R^2\)</span>.</li>
</ul>
<p><strong>Backward Elimination</strong></p>
<ul>
<li>Start with all variables in the model.</li>
<li>Remove the predictor with the highest p-value.</li>
<li>Run the model again and repeat.<br />
</li>
<li>Stop when all p-values for predictors are less than the <em>a priori</em> set critical level.</li>
</ul>
<p><br>
Note that we can have different criteria for selecting models in this stepwise approach, for instance, choosing the model with the biggest decrease in AIC.</p>
</div>
<div class="question-begin">
Question 6
</div>
<div class="question-body">
<p>Using the backward elimination approach, construct a final model to predict wellbeing scores using the <code>mwdata2</code> dataset from above.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-123" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-123&#39;, &#39;sol-start-123&#39;)"></span>
</div>
<div id="sol-body-123" class="solution-body" style="display: none;">
<p>We will stop when all p-values are <span class="math inline">\(&lt;.05\)</span></p>
<p>Note that we have two variables in there which are direct transformations of one another - “location” and “isRural.” We can’t have both.</p>
<pre class="r"><code>summary(mwdata2)</code></pre>
<pre><code>##       age         outdoor_time     social_int       routine        wellbeing   
##  Min.   :18.00   Min.   : 1.00   Min.   : 3.00   Min.   :0.000   Min.   :22.0  
##  1st Qu.:30.00   1st Qu.:12.75   1st Qu.: 9.00   1st Qu.:0.000   1st Qu.:33.0  
##  Median :42.00   Median :18.00   Median :12.00   Median :1.000   Median :35.0  
##  Mean   :42.30   Mean   :18.25   Mean   :12.06   Mean   :0.565   Mean   :36.3  
##  3rd Qu.:54.25   3rd Qu.:23.00   3rd Qu.:15.00   3rd Qu.:1.000   3rd Qu.:40.0  
##  Max.   :70.00   Max.   :35.00   Max.   :24.00   Max.   :1.000   Max.   :59.0  
##                                                                                
##    location            steps_k         isRural         
##  Length:200         Min.   :  0.00   Length:200        
##  Class :character   1st Qu.: 24.00   Class :character  
##  Mode  :character   Median : 42.45   Mode  :character  
##                     Mean   : 44.93                     
##                     3rd Qu.: 65.28                     
##                     Max.   :111.30                     
##                     NA&#39;s   :66</code></pre>
<pre class="r"><code>full_model &lt;- lm(wellbeing ~ age + outdoor_time + social_int + routine + location + steps_k, data = mwdata2)
summary(full_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wellbeing ~ age + outdoor_time + social_int + routine + 
##     location + steps_k, data = mwdata2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -11.567  -2.901  -0.050   2.919   9.416 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    29.289216   2.094310  13.985  &lt; 2e-16 ***
## age             0.018316   0.026404   0.694 0.489155    
## outdoor_time    0.145573   0.061363   2.372 0.019189 *  
## social_int      0.357076   0.098317   3.632 0.000408 ***
## routine         3.039223   0.788248   3.856 0.000183 ***
## locationrural  -5.176386   0.974776  -5.310 4.78e-07 ***
## locationsuburb  0.075809   1.114115   0.068 0.945858    
## steps_k         0.006114   0.016434   0.372 0.710489    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.457 on 126 degrees of freedom
##   (66 observations deleted due to missingness)
## Multiple R-squared:  0.3707, Adjusted R-squared:  0.3358 
## F-statistic:  10.6 on 7 and 126 DF,  p-value: 1.926e-10</code></pre>
<p>We will remove the “steps_k” variable, as it is the predictor with the highest p-value (don’t be tempted to think that “location” has the highest p-value. The estimated difference between urban and suburban does indeed have a high p-value, but the difference between rural and urban has a very low p-value).</p>
<pre class="r"><code>model1 &lt;- lm(wellbeing ~ age + outdoor_time + social_int + routine + location, data = mwdata2)
summary(model1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wellbeing ~ age + outdoor_time + social_int + routine + 
##     location, data = mwdata2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.9173  -2.6865  -0.2971   2.8334  14.6234 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    29.76995    1.65807  17.955  &lt; 2e-16 ***
## age            -0.01079    0.02043  -0.528    0.598    
## outdoor_time    0.17452    0.04295   4.063 7.03e-05 ***
## social_int      0.38733    0.07592   5.102 8.01e-07 ***
## routine         2.95814    0.61145   4.838 2.68e-06 ***
## locationrural  -4.97721    0.71808  -6.931 6.09e-11 ***
## locationsuburb -0.27975    0.86795  -0.322    0.748    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.278 on 193 degrees of freedom
## Multiple R-squared:  0.3896, Adjusted R-squared:  0.3707 
## F-statistic: 20.53 on 6 and 193 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>And now the “age” variable:</p>
<pre class="r"><code>model2 &lt;- lm(wellbeing ~ outdoor_time + social_int + routine + location, data = mwdata2)
summary(model2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wellbeing ~ outdoor_time + social_int + routine + 
##     location, data = mwdata2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.8649  -2.6977  -0.2127   2.5935  14.8263 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    29.28101    1.37298  21.327  &lt; 2e-16 ***
## outdoor_time    0.17561    0.04282   4.101 6.04e-05 ***
## social_int      0.38815    0.07576   5.123 7.21e-07 ***
## routine         2.95193    0.61020   4.838 2.67e-06 ***
## locationrural  -4.96317    0.71625  -6.929 6.08e-11 ***
## locationsuburb -0.28431    0.86630  -0.328    0.743    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.27 on 194 degrees of freedom
## Multiple R-squared:  0.3888, Adjusted R-squared:  0.373 
## F-statistic: 24.68 on 5 and 194 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In this model, all our predictors have p-values lower than our critical level of <span class="math inline">\(.05\)</span>.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 7
</div>
<div class="question-body">
<p>There are functions in R which automate the stepwise procedure for us.<br />
<code>step(&lt;modelname&gt;)</code> will by default use backward elimination to choose the model with the lowest AIC.</p>
<ol style="list-style-type: decimal">
<li>Using data on the Big 5 Personality traits, perceptions of social ranks, and depression and anxiety, fit the full model to predict DASS-21 scores.</li>
<li>Use <code>step()</code> to determine which predictors to keep in your model.</li>
<li>What predictors do you have in your final model?</li>
</ol>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-124" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-124&#39;, &#39;sol-start-124&#39;)"></span>
</div>
<div id="sol-body-124" class="solution-body" style="display: none;">
<pre class="r"><code>full_dass_model &lt;- lm(dass ~ zn*scs_mc + zo + zc + ze + za + zn, data = scs_study)
step(full_dass_model)</code></pre>
<pre><code>## Start:  AIC=2374.99
## dass ~ zn * scs_mc + zo + zc + ze + za + zn
## 
##             Df Sum of Sq   RSS    AIC
## - zc         1      2.05 23915 2373.0
## - za         1     11.06 23924 2373.3
## - zo         1     22.82 23936 2373.6
## &lt;none&gt;                   23913 2375.0
## - ze         1    147.25 24060 2377.0
## - zn:scs_mc  1   2340.68 26254 2434.2
## 
## Step:  AIC=2373.04
## dass ~ zn + scs_mc + zo + ze + za + zn:scs_mc
## 
##             Df Sum of Sq   RSS    AIC
## - za         1     10.66 23926 2371.3
## - zo         1     23.28 23938 2371.7
## &lt;none&gt;                   23915 2373.0
## - ze         1    148.17 24063 2375.1
## - zn:scs_mc  1   2339.57 26255 2432.3
## 
## Step:  AIC=2371.33
## dass ~ zn + scs_mc + zo + ze + zn:scs_mc
## 
##             Df Sum of Sq   RSS    AIC
## - zo         1     22.33 23948 2369.9
## &lt;none&gt;                   23926 2371.3
## - ze         1    497.48 24423 2382.8
## - zn:scs_mc  1   2340.17 26266 2430.6
## 
## Step:  AIC=2369.95
## dass ~ zn + scs_mc + ze + zn:scs_mc
## 
##             Df Sum of Sq   RSS    AIC
## &lt;none&gt;                   23948 2369.9
## - ze         1     496.1 24444 2381.4
## - zn:scs_mc  1    2318.4 26266 2428.6</code></pre>
<pre><code>## 
## Call:
## lm(formula = dass ~ zn + scs_mc + ze + zn:scs_mc, data = scs_study)
## 
## Coefficients:
## (Intercept)           zn       scs_mc           ze    zn:scs_mc  
##     44.9311       1.5566      -0.4471       0.8708      -0.5153</code></pre>
</div>
<p class="solution-end">
</p>
<hr />
<p>Extra reading: <a href="http://joshualoftus.com/post/model-selection-bias-invalidates-significance-tests/">Joshua Loftus’ Blog: Model selection bias invalidates significance tests</a></p>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>

<link rel="stylesheet" href="https://uoepsy.github.io/assets/css/ccfooter.css" />
<div class="ccfooter"></div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
