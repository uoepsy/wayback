<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Two-way ANOVA</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-plus')) {
    f.classList.add('fa-minus')
    f.classList.remove('fa-plus')
} else {
    f.classList.add('fa-plus')
    f.classList.remove('fa-minus')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>DAPR2</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fas fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Simple Linear Regression
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_models.html">1/1: Functions and models</a>
    </li>
    <li>
      <a href="02_slr.html">1/2: Simple linear regression</a>
    </li>
    <li>
      <a href="03_slr_model_fit.html">1/3: Model Fit, Standardized Coefficients</a>
    </li>
    <li>
      <a href="04_slr_assumptions.html">1/4: Assumptions &amp; Diagnostics</a>
    </li>
    <li>
      <a href="05_slr_writeup.html">1/5: Writing-up</a>
    </li>
    <li class="dropdown-header">1/6: Break week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Multiple Linear Regression
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06_mlr.html">1/7: Basics</a>
    </li>
    <li>
      <a href="07_mlr_int.html">1/8: Interactions</a>
    </li>
    <li>
      <a href="08_mlr_assumpt.html">1/9: Assumptions &amp; Diagnostics</a>
    </li>
    <li>
      <a href="09_mlr_select.html">1/10: Model Fit, Model Comparison, Model Selection</a>
    </li>
    <li>
      <a href="10_mlr_report.html">1/11: Writing-up</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Experimental Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="11_anova.html">2/1: ANOVA</a>
    </li>
    <li>
      <a href="11_anova.html">2/2: ANOVA (again)</a>
    </li>
    <li>
      <a href="12_factorial_anova.html">2/3: 2x2 ANOVA</a>
    </li>
    <li>
      <a href="13_multiplecomp.html">2/4: Multiple Comparisons</a>
    </li>
    <li class="dropdown-header">2/5: No exercises</li>
    <li class="dropdown-header">2/6: Break week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced Topics for LM
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="14_bootstrap_reg.html">2/7: Bootstrap</a>
    </li>
    <li>
      <a href="15_binary_logistic.html">2/8: Binary Logistic Regression</a>
    </li>
    <li>
      <a href="16_more_about_logistic.html">2/9: More About Logistic Regression</a>
    </li>
    <li>
      <a href="17_power_regression.html">2/10: Sample Size and Power Analysis</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Help
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="intro_r_rstudio.html">Getting started with R &amp; RStudio</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Two-way ANOVA</h1>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In this week’s exercises, you will learn how to measure the effect of two factors on a response variable of interest. We will try to answer questions such as:</p>
<ul>
<li>Does level <span class="math inline">\(i\)</span> of the first factor have an effect on the response?</li>
<li>Does level <span class="math inline">\(j\)</span> of the second factor have an effect on the response?</li>
<li>Is there a combined effect of level <span class="math inline">\(i\)</span> of the first factor and level <span class="math inline">\(j\)</span> of the second factor on the response? In other words, is there interaction of the two factors so that the combined effect is not simply the additive effect of level <span class="math inline">\(i\)</span> of the first factor plus the effect of level <span class="math inline">\(j\)</span> of the second factor?</li>
</ul>
<p>To that end, we will consider an example cognitive neuroscience study comparing the performance of different patient groups on a series of tasks.</p>
</div>
<div id="research-question-and-data" class="section level1">
<h1>Research question and data</h1>
<p>A group of researchers wants to test an hypothesised theory according to which patients with amnesia will have a deficit in explicit memory but not on implicit memory. Huntingtons patients, on the other hand, will be just the opposite: they will have no deficit in explicit memory, but will have a deficit in implicit memory.</p>
<p>The researchers designed a study yielding a <span class="math inline">\(3 \times 3\)</span> factorial design to test this theory.
The first factor, “Diagnosis,” classifies the three types of individuals:</p>
<ul>
<li>1 denotes amnesic patients;</li>
<li>2 denotes Huntingtons patients; and</li>
<li>3 denotes a control group of individuals with no known neurological disorder.</li>
</ul>
<p>The second factor, “Task,” tells us to which of three tasks each study participant was randomly assigned to:</p>
<ul>
<li>1 = artificial grammar task, which consists of classifying letter sequences as either following or not following grammatical rules;</li>
<li>2 = classification learning task, which consists of classifying hypothetical patients as either having or not having a certain disease based on symptoms probabilistically related to the disease; and</li>
<li>3 = recognition memory task, which consists of recognising particular stimuli as stimuli that have previously been presented during the task.</li>
</ul>
<p>The following table presents the recorded data for 15 amnesiacs, 15 Huntington individuals, and 15 controls.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Task
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Diagnosis
</th>
<th style="text-align:left;">
grammar
</th>
<th style="text-align:left;">
classification
</th>
<th style="text-align:left;">
recognition
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
amnesic
</td>
<td style="text-align:left;">
44, 63, 76, 72, 45
</td>
<td style="text-align:left;">
72, 66, 55, 82, 75
</td>
<td style="text-align:left;">
70, 51, 82, 66, 56
</td>
</tr>
<tr>
<td style="text-align:left;">
huntingtons
</td>
<td style="text-align:left;">
24, 30, 51, 55, 40
</td>
<td style="text-align:left;">
53, 59, 33, 37, 43
</td>
<td style="text-align:left;">
107, 80, 98, 82, 108
</td>
</tr>
<tr>
<td style="text-align:left;">
control
</td>
<td style="text-align:left;">
76, 98, 71, 70, 85
</td>
<td style="text-align:left;">
92, 65, 86, 67, 90
</td>
<td style="text-align:left;">
107, 80, 101, 82, 105
</td>
</tr>
</tbody>
</table>
<p>Keep in mind that each person has been randomly assigned to one of the three tasks, so there are five observations per cell of the design.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>The tasks chosen by the researchers have been picked to map onto the theoretical differences between the three types of research participants.
The first two tasks (grammar and classification) are known to reflect implicit memory processes, whereas the recognition task is known to reflect explicit memory processes.
If the theory is correct, we would expect to see relatively higher scores on the first two tasks for the amnesiac group but relatively higher scores on the third task for the Huntington group.</p>
<p><br></p>
<div class="optional-begin">
Data: cognitive_experiment.csv. Click the plus to expand →<span id="opt-start-151" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-151&#39;, &#39;opt-start-151&#39;)"></span>
</div>
<div id="opt-body-151" class="optional-body" style="display: none;">
<p><strong>Download link</strong></p>
<p><a href="https://uoepsy.github.io/data/cognitive_experiment.csv">Download the data here</a></p>
<p><strong>Preview</strong></p>
<p>The first six rows of the data are:</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Diagnosis
</th>
<th style="text-align:center;">
Task
</th>
<th style="text-align:center;">
Y
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
44
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
63
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
76
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
72
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
45
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
72
</td>
</tr>
</tbody>
</table>
</div>
<p class="optional-end">
</p>
</div>
<div id="exploratory-analysis" class="section level1">
<h1>Exploratory analysis</h1>
<div class="question-begin">
Question 1
</div>
<div class="question-body">
<p>Load the tidyverse library and read the cognitive experiment data into R.</p>
<p>Convert categorical variables into factors, and assign more informative labels to the factor levels according to the data description provided above.</p>
<p>Relevel the <code>Diagnosis</code> factor to have “Control” as the reference group. (Hint: Use the <code>fct_relevel</code> function).</p>
<p>Rename the response variable from <code>Y</code> to <code>Score</code>.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-152" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-152&#39;, &#39;sol-start-152&#39;)"></span>
</div>
<div id="sol-body-152" class="solution-body" style="display: none;">
<p>Load the tidyverse library and read the data into R:</p>
<pre class="r"><code>library(tidyverse)

cog &lt;- read_csv(&#39;https://uoepsy.github.io/data/cognitive_experiment.csv&#39;)
head(cog)</code></pre>
<pre><code>## # A tibble: 6 x 3
##   Diagnosis  Task     Y
##       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1         1     1    44
## 2         1     1    63
## 3         1     1    76
## 4         1     1    72
## 5         1     1    45
## 6         1     2    72</code></pre>
<p>We will now convert <code>Diagnosis</code> and <code>Task</code> into factors, making the labels of each factor level more meaningful.</p>
<p>According to the data description, the encoding of the factor <code>Diagnosis</code> is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 are control patients.</p>
<pre class="r"><code>cog$Diagnosis &lt;- factor(cog$Diagnosis, 
                        labels = c(&quot;amnesic&quot;, &quot;huntingtons&quot;, &quot;control&quot;), 
                        ordered = FALSE)</code></pre>
<p>The encoding for the factor <code>Task</code> is: 1 = grammar task, 2 = classification task, and 3 = recognition task.</p>
<pre class="r"><code>cog$Task &lt;- factor(cog$Task, 
                   labels = c(&quot;grammar&quot;, &quot;classification&quot;, &quot;recognition&quot;), 
                   ordered = FALSE)</code></pre>
<p>Relevel the <code>Diagnosis</code> factor so that the reference group is “Control”:</p>
<pre class="r"><code>cog$Diagnosis &lt;- fct_relevel(cog$Diagnosis, &quot;control&quot;)</code></pre>
<p>Rename the response:</p>
<pre class="r"><code>cog &lt;- cog %&gt;%
    rename(Score = Y)</code></pre>
<p>Look at the data:</p>
<pre class="r"><code>head(cog)</code></pre>
<pre><code>## # A tibble: 6 x 3
##   Diagnosis Task           Score
##   &lt;fct&gt;     &lt;fct&gt;          &lt;dbl&gt;
## 1 amnesic   grammar           44
## 2 amnesic   grammar           63
## 3 amnesic   grammar           76
## 4 amnesic   grammar           72
## 5 amnesic   grammar           45
## 6 amnesic   classification    72</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 2
</div>
<div class="question-body">
<p>Create some exploratory plots showing</p>
<ul>
<li>the joint distribution of diagnosis and task;</li>
<li>how the patient scores vary across the tasks;</li>
<li>how the patient scores vary across the diagnoses;</li>
<li>how the patient scores vary between the different diagnostic groups and tasks. This is called an interaction plot.</li>
</ul>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-153" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-153&#39;, &#39;sol-start-153&#39;)"></span>
</div>
<div id="sol-body-153" class="solution-body" style="display: none;">
<p>Let’s study the joint distribution of the two factors using a segmented bar chart:</p>
<pre class="r"><code>ggplot(cog, aes(x = Diagnosis, fill = Task)) +
    geom_bar()</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-10-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>There were 15 control patients, 15 amnesic patients, and 15 Huntingtons patients. For each diagnosis, five patients were randomly assigned to take either a grammar, a classification, or a recognition task.</p>
<p>The following plot shows how the patient scores vary across the tasks:</p>
<pre class="r"><code>ggplot(cog, aes(x = Task, y = Score, color = Task)) +
    geom_boxplot()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:boxplot-task"></span>
<img src="12_factorial_anova_files/figure-html/boxplot-task-1.png" alt="Distribution of scores by tasks." width="60%" />
<p class="caption">
Figure 1: Distribution of scores by tasks.
</p>
</div>
<p>The next plot shows how the patient scores vary across the diagnosis:</p>
<pre class="r"><code>ggplot(cog, aes(x = Diagnosis, y = Score, color = Diagnosis)) +
    geom_boxplot()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:boxplot-diagnosis"></span>
<img src="12_factorial_anova_files/figure-html/boxplot-diagnosis-1.png" alt="Distribution of scores by dignoses." width="60%" />
<p class="caption">
Figure 2: Distribution of scores by dignoses.
</p>
</div>
<p>The following <strong>interaction plot</strong> displays the average score, plus or minus two standard errors of the mean, for the different combinations of diagnosis and task.
The mean plus or minus one standard error covers approximately 95% of the values, see <a href="https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule">this Wikipedia article</a>.</p>
<pre class="r"><code>cog_stats &lt;- cog %&gt;% 
    group_by(Diagnosis, Task) %&gt;%
    summarise(
        Avg_Score = mean(Score), 
        SE = sd(Score) / sqrt(n())
    )
cog_stats</code></pre>
<pre><code>## # A tibble: 9 x 4
## # Groups:   Diagnosis [3]
##   Diagnosis   Task           Avg_Score    SE
##   &lt;fct&gt;       &lt;fct&gt;              &lt;dbl&gt; &lt;dbl&gt;
## 1 control     grammar               80  5.22
## 2 control     classification        80  5.81
## 3 control     recognition           95  5.81
## 4 amnesic     grammar               60  6.67
## 5 amnesic     classification        70  4.55
## 6 amnesic     recognition           65  5.44
## 7 huntingtons grammar               40  5.92
## 8 huntingtons classification        45  4.86
## 9 huntingtons recognition           95  5.98</code></pre>
<pre class="r"><code>ggplot(data = cog_stats, aes(x = Task, y = Avg_Score, color = Diagnosis)) +
    geom_point(size = 3) +
    geom_linerange(aes(ymin = Avg_Score - 2 * SE, ymax = Avg_Score + 2 * SE)) +
    geom_line(aes(x = as.numeric(Task)))</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The interaction plot suggests the presence of a significant interaction between diagnosis and task in the data.</p>
<p>Control patients consistently perform best across all tasks. They don’t seem to differ substantially in their scores between grammar and classification tasks, but they clearly perform better in the recognition task than the grammar and classification ones.</p>
<p>Amnesic patients appear to perform better than Huntingtons patients in grammar an classification tasks (reflecting intrinsic memory processes) and perform worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes).</p>
</div>
<p class="solution-end">
</p>
</div>
<div id="model-fitting" class="section level1">
<h1>Model fitting</h1>
<p>The study involves two factors with three levels each. For each combination of factor levels we have 5 observations. The five observations are assumed to come from a population having a specific mean. The population means corresponding to each combination of factor levels can be schematically written as:</p>
<p><span class="math display">\[
\begin{matrix}
                   &amp;         &amp;         &amp; \textbf{Task} &amp; \\
                   &amp;         &amp; (j=1)\text{ grammar} &amp; (j=2)\text{ classification} &amp; (j=3)\text{ recognition} \\
                   &amp; (i=1)\text{ control} &amp; \mu_{1,1} &amp; \mu_{1,2} &amp; \mu_{1,3} \\
\textbf{Diagnosis} &amp; (i=2)\text{ amnesic} &amp; \mu_{2,1} &amp; \mu_{2,2} &amp; \mu_{2,3} \\
                   &amp; (i=3)\text{ huntingtons} &amp; \mu_{3,1} &amp; \mu_{3,2} &amp; \mu_{3,3}
\end{matrix}
\]</span></p>
<p><br></p>
<p><strong>Additive model</strong></p>
<p>The additive two-way ANOVA model has the form
<span class="math display">\[
Score_{i,j,k} = Intercept + DiagnosisEffect_i + TaskEffect_j + Error_{i,j,k} \qquad \begin{cases}
i = 1, 2, 3 \\
j = 1, 2, 3 \\
k = 1, ..., 5
\end{cases}
\]</span>
where:</p>
<ul>
<li><span class="math inline">\(i = 1, 2, 3\)</span> counts the levels of the first factor (Diagnosis);</li>
<li><span class="math inline">\(j = 1, 2, 3\)</span> counts the levels of the second factor (Task);</li>
<li><span class="math inline">\(k = 1, ..., 5\)</span> counts the observations within each combination of factor levels;</li>
<li><span class="math inline">\(Score_{i,j,k}\)</span> is the <span class="math inline">\(k\)</span>th score measured at level <span class="math inline">\(i\)</span> of Diagnosis and level <span class="math inline">\(j\)</span> of Task;</li>
<li><span class="math inline">\(Intercept\)</span> is the model intercept;</li>
<li><span class="math inline">\(DiagnosisEffect_i\)</span> represents the effect of level <span class="math inline">\(i\)</span> of Diagnosis;</li>
<li><span class="math inline">\(TaskEffect_j\)</span> represents the effect of level <span class="math inline">\(j\)</span> of Task.</li>
</ul>
<p>As last week, the interpretation of <span class="math inline">\(Intercept\)</span> will change depending on the side-constraint used.
This week we will be using the reference group constraint (<code>contr.treatment</code>), which is what R uses by default.</p>
<p><br></p>
<p><strong>Reference group constraint</strong></p>
<p>Under the reference group constraint, the intercept represents the mean response at the first level of each factor, that is when Diagnosis is “control” and Task = “grammar.”</p>
<p>The terms <span class="math inline">\(DiagnosisEffect_i\)</span> and <span class="math inline">\(TaskEffect_j\)</span> correspond, respectively, to the effect of level <span class="math inline">\(i\)</span> of the first factor and level <span class="math inline">\(j\)</span> of the second factor.</p>
<p>The reference group constraint in the two-factor case is a simple generalisation of the constraint we saw last week:</p>
<p><span class="math display">\[
\begin{aligned}
Intercept &amp;= \mu_{1,1} \\
DiagnosisEffect_1 &amp;= 0 \\
TaskEffect_1 &amp;= 0 
\end{aligned}
\]</span></p>
<p>The cell means are obtained as:</p>
<p><span class="math display">\[
{
\scriptsize
\begin{matrix}
                   &amp;         &amp; \textbf{Task} &amp; \\
\textbf{Diagnosis} &amp; (j=1)\text{ grammar} &amp; (j=2)\text{ classification} &amp; (j=3)\text{ recognition} \\
(i=1)\text{ control} &amp; Intercept &amp; Intecept + TaskEffect_2 &amp; Intercept + TaskEffect_3 \\
(i=2)\text{ amnesic} &amp; Intercept + DiagnosisEffect_2 &amp; Intercept + DiagnosisEffect_2 + TaskEffect_2 &amp; Intercept + DiagnosisEffect_2 + TaskEffect_3 \\
(i=3)\text{ huntingtons} &amp; Intercept + DiagnosisEffect_3 &amp; Intercept + DiagnosisEffect_3 + TaskEffect_2 &amp; Intercept + DiagnosisEffect_3 + TaskEffect_3
\end{matrix}
}
\]</span></p>
<p><br></p>
<p><strong>Sum to zero constraint</strong></p>
<p>If, instead, we use the sum to zero constraint, we would have that</p>
<p><span class="math display">\[
\begin{aligned}
Intercept &amp;= \frac{\mu_{1,1} + \mu_{1,2} + \cdots + \mu_{3,3}}{9} = \text{global mean} \\
DiagnosisEffect_3 &amp;= -(DiagnosisEffect_1 + DiagnosisEffect_2) \\
TaskEffect_3 &amp;= -(TaskEffect_1 + TaskEffect_2)
\end{aligned}
\]</span></p>
<p>meaning that the intercept would now represent the overall or global mean, and the last effect for each factor would not be shown in the R output as it can be found using the side-constraint as minus the sum of the remaining effects for that factor.</p>
<p><br></p>
<p><strong>Cognitive experiment continued</strong></p>
<p>Let’s go back to the cognitive experiment data…</p>
<p>From the exploratory analysis performed in question 2, it seems that both task and diagnosis factors might help predict a patient score.</p>
<div class="question-begin">
Question 3
</div>
<div class="question-body">
<p>Fit a linear model which makes use of the two factors <code>Diagnosis</code> and <code>Task</code> to predict the patients’ <code>Score</code>. Call the fitted model <code>mdl_add</code>.</p>
<p>Comment on the F-test for model utility returned by <code>summary(mdl_add)</code>, as well as the t-test for the significance of the model coefficients.</p>
<p>Furthermore, look at the <code>anova(mdl_add)</code> and comment on whether <em>Diagnosis</em> impacts scores on the test and whether each <em>Task</em> affects the score.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-154" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-154&#39;, &#39;sol-start-154&#39;)"></span>
</div>
<div id="sol-body-154" class="solution-body" style="display: none;">
<pre class="r"><code>mdl_add &lt;- lm(Score ~ 1 + Diagnosis + Task, data = cog)</code></pre>
<p><br></p>
<p><strong>Summary output and model coefficients</strong></p>
<p>Let’s now inspect the output of the <code>summary</code> function:</p>
<pre class="r"><code>summary(mdl_add)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Score ~ 1 + Diagnosis + Task, data = cog)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##    -29    -12      1     10     33 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            75.000      5.447  13.770  &lt; 2e-16 ***
## Diagnosisamnesic      -20.000      5.967  -3.352 0.001762 ** 
## Diagnosishuntingtons  -25.000      5.967  -4.190 0.000149 ***
## Taskclassification      5.000      5.967   0.838 0.407009    
## Taskrecognition        25.000      5.967   4.190 0.000149 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 16.34 on 40 degrees of freedom
## Multiple R-squared:  0.4958, Adjusted R-squared:  0.4453 
## F-statistic: 9.831 on 4 and 40 DF,  p-value: 1.233e-05</code></pre>
<p>The null hypothesis for the F-test of model utility is that:</p>
<p><span class="math display">\[
H_0 : \begin{cases}
DiagnosisEffect_2 = DiagnosisEffect_3 = 0 \\
TaskEffect_2 = TaskEffect_3 = 0
\end{cases}
\]</span></p>
<p>The result of the F-test of model utility tells us that both diagnosis and task are useful predictors of patient scores.</p>
<div class="int">
<p>At the 5% significance level, we performed an F-test for model utility, <span class="math inline">\(F(4,40) = 9.831, p &lt;.001\)</span>.
If diagnosis and task were not useful in predicting patient scores, we would obtain sample results as extreme or more extreme than the ones observed only one out of 10,000 times. Hence, the data provide very strong evidence that both predictors are useful.</p>
</div>
<p>Looking at the t-test for the significance of the model coefficients, it appears that the only non-significant coefficient is the effect of the classification task.
This means that the population mean score for the classification task is the same as the population mean score for the grammar task (reference group).
This is in agreement with Figure <a href="#fig:boxplot-task">1</a>, where you can see that the main effect of the classification task is not significantly different from that of the grammar task.</p>
<p><br></p>
<p><strong>ANOVA table</strong></p>
<p>The output of <code>anova</code> is:</p>
<pre class="r"><code>anova(mdl_add)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: Score
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Diagnosis  2   5250    2625  9.8315 0.0003366 ***
## Task       2   5250    2625  9.8315 0.0003366 ***
## Residuals 40  10680     267                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The ANOVA analysis splits up the total variation into three sources: the variation due to the different diagnosis, the variation due to different task, and the residual variation.</p>
<p>Both F-ratios are large. Looking back at the boxplots in Figure <a href="#fig:boxplot-task">1</a> and <a href="#fig:boxplot-diagnosis">2</a>, we shouldn’t be surprised.</p>
<p>It was clear that there were differences in scores among the different diagnoses (control, amnesic, and Huntingtons patients) even without accounting for the fact that each level contained three different tasks.</p>
<p>Similarly, there were clear differences in cognitive scores across the three tasks (grammar, classification, and recognition).</p>
<p>The two null hypotheses to test are</p>
<ul>
<li><p>No effect due to the <em>Diagnosis</em> factor:</p>
<p><span class="math display">\[
H_0 : DiagnosisEffect_1 = DiagnosisEffect_2 = DiagnosisEffect_3 = 0
\]</span></p></li>
<li><p>No effect due to the <em>Task</em> factor:</p>
<p><span class="math display">\[
H_0 : TaskEffect_1 = TaskEffect_2 = TaskEffect_3 = 0
\]</span></p></li>
</ul>
<p>The p-value for <em>Diagnosis</em> (&lt;.001) is very small, indicating that (not surprisingly) there are differences in cognitive scores between the four diagnoses.</p>
<p>The small p-value for <em>Task</em> (&lt;.001) indicates that, after accounting for the differences due to the diagnosis, we can detect (at a 5% level) an effect on the cognitive scores due to the assigned task.</p>
<p>We could say:</p>
<div class="int">
<p>The F-ratio for <em>Diagnosis</em> is 9.83. The probability of an F-ratio that big occurring by chance is very small (&lt;.001). So, we can reject the null hypothesis that the effects of control, amnesic and Huntingtons are all zero and conclude that there is an effect on the cognitive scores due to the patient’s diagnosis.</p>
</div>
<div class="int">
<p>The F-ratio for <em>Task</em> of 9.83 with a p-value &lt;.001 leads us to reject the null hypothesis about task effects as well. We conclude that the tasks taken by the patients impact the cognitive scores.</p>
</div>
<p><br></p>
<p><strong>Assumption checks</strong></p>
<p>Of course, there will be assumptions and conditions to check. The good news is that most are the same as for linear regression.
The only difference is that linearity is now replaced by checking whether the errors in each group have mean zero.</p>
<pre class="r"><code>par(mfrow = c(2,2))
plot(mdl_add)</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-15-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The residuals for each group do not seem to be randomly scattered around zero. Some groups have a higher mean than others. This indicates that the model has not captured all the systematic trend in the data, and some is leftover in the residuals. The model needs to be changed to meet the zero mean errors assumption.</p>
<p>The residuals seem to come from a normal distribution, and the spread of the residuals in each group seems roughly constant.</p>
<p>Because the zero-mean condition is violated, we will soon change the model to see if we can capture the remaining trend in the data and leave residuals with zero mean.
To do so, in light of the strong interaction present in the data, we will add an interaction term to our model.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 4
</div>
<div class="question-body">
<p>Use the additive model fitted above to predict the average score for each combination of the factor levels. (Hint: use the <code>predict()</code> function)</p>
<p>Create a plot showing how the predicted averages vary by diagnosis and task.</p>
<p>Does this match to the last plot created in question 2?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-155" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-155&#39;, &#39;sol-start-155&#39;)"></span>
</div>
<div id="sol-body-155" class="solution-body" style="display: none;">
<p>Create the combination of factor levels for which we want a prediction:</p>
<pre class="r"><code>treatments &lt;- expand_grid(
    Diagnosis = fct_relevel(c(&quot;control&quot;, &quot;amnesic&quot;, &quot;huntingtons&quot;), &quot;control&quot;),
    Task = fct_relevel(c(&quot;grammar&quot;, &quot;classification&quot;, &quot;recognition&quot;), &quot;grammar&quot;)
)
head(treatments)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   Diagnosis Task          
##   &lt;fct&gt;     &lt;fct&gt;         
## 1 control   grammar       
## 2 control   classification
## 3 control   recognition   
## 4 amnesic   grammar       
## 5 amnesic   classification
## 6 amnesic   recognition</code></pre>
<p>Provide the levels for which we want a prediction to the <code>predict()</code> function:</p>
<pre class="r"><code>pred_add &lt;- treatments %&gt;%
    mutate(Pred_Score = predict(mdl_add, newdata = treatments))
head(pred_add)</code></pre>
<pre><code>## # A tibble: 6 x 3
##   Diagnosis Task           Pred_Score
##   &lt;fct&gt;     &lt;fct&gt;               &lt;dbl&gt;
## 1 control   grammar                75
## 2 control   classification         80
## 3 control   recognition           100
## 4 amnesic   grammar                55
## 5 amnesic   classification         60
## 6 amnesic   recognition            80</code></pre>
<p>Create an interaction plot:</p>
<pre class="r"><code>ggplot(pred_add, aes(x = Task, y = Pred_Score, color = Diagnosis)) +
    geom_point() +
    geom_line(aes(x = as.numeric(Task)))</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-18-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>It seems like the additive model doesn’t capture well the trend in the data. According to the additive model, the effect of Task remains constant across the different types of patients (Diagnosis).</p>
<p>However, the interaction plot created during our exploratory analysis (question 2) highlighted that the task effect is not constant across all groups of patients: the two factors interact.</p>
</div>
<p class="solution-end">
</p>
<p><strong>Interaction model</strong></p>
<p>An interaction model also allows for the interaction of the two factors. That is, the effect of level <span class="math inline">\(i\)</span> of one factor can be different depending on level <span class="math inline">\(j\)</span> of the second factor. For example, the effect of amnesia (<span class="math inline">\(i=2\)</span>) might increase the response in grammar tasks (<span class="math inline">\(j=1\)</span>), while it might decrease the response in recognition tasks (<span class="math inline">\(j=3\)</span>).</p>
<p>The two-way ANOVA model with interaction is:</p>
<p><span class="math display">\[
Score_{i,j,k} = Intercept + DiagnosisEffect_i + TaskEffect_j + InteractionEffect_{i,j} + Error_{i,j,k}
\]</span></p>
<p>where the constraints on the interaction are such that whenever <span class="math inline">\(i=1\)</span> OR <span class="math inline">\(j=1\)</span>, the coefficient is 0:</p>
<p><span class="math display">\[
\begin{aligned}
InteractionEffect_{1,1} &amp;= 0 \qquad InteractionEffect_{1,2} = 0  \qquad \qquad InteractionEffect_{1,3} = 0 \\
InteractionEffect_{2,1} &amp;= 0 \\
InteractionEffect_{3,1} &amp;= 0 
\end{aligned}
\]</span></p>
<div class="question-begin">
Question 5
</div>
<div class="question-body">
<p>Update the previously fitted additive model to also include an interaction term for <code>Diagnosis</code> and <code>Task</code>. Call the fitted model <code>mdl_int</code>.</p>
<p>Comment on the model output.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-156" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-156&#39;, &#39;sol-start-156&#39;)"></span>
</div>
<div id="sol-body-156" class="solution-body" style="display: none;">
<p>Fit the interaction model:</p>
<pre class="r"><code>mdl_int &lt;- lm(Score ~ 1 + Diagnosis + Task + Diagnosis:Task, data = cog)</code></pre>
<p>Alternatively, you could have used the following shorter version:</p>
<pre class="r"><code>mdl_int &lt;- lm(Score ~ 1 + Diagnosis * Task, data = cog)</code></pre>
<p>Let’s look at the summary:</p>
<pre class="r"><code>summary(mdl_int)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Score ~ 1 + Diagnosis + Task + Diagnosis:Task, data = cog)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##    -16    -12      2     11     18 
## 
## Coefficients:
##                                           Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)                              8.000e+01  5.617e+00  14.241 2.30e-16
## Diagnosisamnesic                        -2.000e+01  7.944e+00  -2.518  0.01641
## Diagnosishuntingtons                    -4.000e+01  7.944e+00  -5.035 1.35e-05
## Taskclassification                       1.461e-14  7.944e+00   0.000  1.00000
## Taskrecognition                          1.500e+01  7.944e+00   1.888  0.06708
## Diagnosisamnesic:Taskclassification      1.000e+01  1.123e+01   0.890  0.37933
## Diagnosishuntingtons:Taskclassification  5.000e+00  1.123e+01   0.445  0.65895
## Diagnosisamnesic:Taskrecognition        -1.000e+01  1.123e+01  -0.890  0.37933
## Diagnosishuntingtons:Taskrecognition     4.000e+01  1.123e+01   3.560  0.00106
##                                            
## (Intercept)                             ***
## Diagnosisamnesic                        *  
## Diagnosishuntingtons                    ***
## Taskclassification                         
## Taskrecognition                         .  
## Diagnosisamnesic:Taskclassification        
## Diagnosishuntingtons:Taskclassification    
## Diagnosisamnesic:Taskrecognition           
## Diagnosishuntingtons:Taskrecognition    ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 12.56 on 36 degrees of freedom
## Multiple R-squared:  0.7318, Adjusted R-squared:  0.6722 
## F-statistic: 12.28 on 8 and 36 DF,  p-value: 2.844e-08</code></pre>
<div class="int">
<p>The F-test for model utility is again significant at the 5% level: <span class="math inline">\(F(8,36) = 12.28, p &lt; .001\)</span>. An F-statistic this large or larger occurring by chance only is very small, hence there is strong evidence that the model coefficients are not all zero in the population.</p>
</div>
<p>In the presence of a significant interaction we <strong>do not</strong> interpret the main effects as their interpretation changes with the level of the other factor.</p>
<pre class="r"><code>anova(mdl_int)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: Score
##                Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Diagnosis       2   5250 2625.00 16.6373  7.64e-06 ***
## Task            2   5250 2625.00 16.6373  7.64e-06 ***
## Diagnosis:Task  4   5000 1250.00  7.9225 0.0001092 ***
## Residuals      36   5680  157.78                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="int">
<p>The interaction between diagnosis and task is significant. At the 5% level, the probability of obtaining an F-statistic as large as 7.92 or larger, if there was no interaction effect, is &lt;.001. This provides very strong evidence against the null hypothesis that effect of task is constant across the different diagnoses.</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 6
</div>
<div class="question-body">
<p>Perform a model comparison between the additive model and the interaction model using the <code>anova()</code> function.</p>
<p>Interpret the result of the model comparison.</p>
<p>Which model will you use to answer the research questions of interest?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-157" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-157&#39;, &#39;sol-start-157&#39;)"></span>
</div>
<div id="sol-body-157" class="solution-body" style="display: none;">
<p>We compared two models:
<span class="math display">\[
\begin{aligned}
M1 &amp;: Score_{i,j,k} = Intercept + DiagnosisEffect_i + TaskEffect_j + Error_{i,j,k} \\
M2 &amp;: Score_{i,j,k} = Intercept + DiagnosisEffect_i + TaskEffect_j + InteractionEffect_{i,j} + Error_{i,j,k}
\end{aligned}
\]</span></p>
<p>The relevant function is <code>anova()</code> with the two models as inputs:</p>
<pre class="r"><code>anova(mdl_add, mdl_int)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Score ~ 1 + Diagnosis + Task
## Model 2: Score ~ 1 + Diagnosis + Task + Diagnosis:Task
##   Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     40 10680                                  
## 2     36  5680  4      5000 7.9225 0.0001092 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="int">
<p>We performed an F-test to compare two nested models: an additive two-factor ANOVA against a two-factor model with interaction. The test results are <span class="math inline">\(F(4, 36) = 7.9225, p &lt; .001\)</span>.
At the 5% significance level, the probability of obtaining an F-statistic as large as 7.92 or larger is &lt;.001.
Hence, the comparison of nested models provides strong evidence against the additive effects model, suggesting that we should use the interaction model (M2) as each factor has a different effect on the response depending the level of the other factor.</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 7
</div>
<div class="question-body">
<p>Generate again a plot showing the predicted mean scores for each combination of levels of the diagnosis and task factors.</p>
<p>Do the predicted values better match the interaction plot created in question 2?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-158" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-158&#39;, &#39;sol-start-158&#39;)"></span>
</div>
<div id="sol-body-158" class="solution-body" style="display: none;">
<pre class="r"><code>pred_int &lt;- treatments %&gt;%
    mutate(Pred_Score = predict(mdl_int, newdata = treatments))
head(pred_int)</code></pre>
<pre><code>## # A tibble: 6 x 3
##   Diagnosis Task           Pred_Score
##   &lt;fct&gt;     &lt;fct&gt;               &lt;dbl&gt;
## 1 control   grammar              80.0
## 2 control   classification       80  
## 3 control   recognition          95  
## 4 amnesic   grammar              60  
## 5 amnesic   classification       70  
## 6 amnesic   recognition          65</code></pre>
<pre class="r"><code>ggplot(pred_int, aes(x = Task, y = Pred_Score, color = Diagnosis)) +
    geom_point() +
    geom_line(aes(x = as.numeric(Task)))</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-25-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The plot does a better job in capturing the effect of the two factors and how the combination of two levels of the factors can either enhance or inhibit a patient’s performance on a task.</p>
<p>We can equivalently use the <code>emmeans</code> package to study interactions. In our original interaction plot, we plotted the mean plus or minus two standard errors.</p>
<pre class="r"><code>library(emmeans)

emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-26-1.png" width="60%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
</div>
<div id="assumption-checking" class="section level1">
<h1>Assumption checking</h1>
<div class="question-begin">
Question 8
</div>
<div class="question-body">
<p>Before interpreting the results of the model it is important to check that the model doesn’t violate the assumptions.</p>
<ul>
<li><p>Are the errors independent?</p></li>
<li><p>Do the errors have a mean of zero?</p></li>
<li><p>Are the group variances equal?</p></li>
<li><p>Is the distribution of the errors normal?</p></li>
</ul>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-159" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-159&#39;, &#39;sol-start-159&#39;)"></span>
</div>
<div id="sol-body-159" class="solution-body" style="display: none;">
<pre class="r"><code>par(mfrow = c(2,2))
plot(mdl_int)</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-27-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>The plot of residuals vs fitted values shows that the residuals in each group are randomly scattered with a mean of zero. The scale location plots shows are fairly constant spread across the different groups.</p>
<pre class="r"><code>library(car)
ncvTest(mdl_int)</code></pre>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 0.01006877, Df = 1, p = 0.92007</code></pre>
<div class="int">
<p>We performed a Breusch-Pagan test against the null hypothesis of constant variance ( <span class="math inline">\(\chi^2(1) = .01, p = .92\)</span>).
At the 5% significance level, the large p-value indicates that if the variance were constant, we would obtain a statistic as extreme or more extreme than 0.01 roughly 92 times out of 100. Hence, the sample results do not provide sufficient evidence to reject the null hypothesis that the errors have constant variance.</p>
</div>
<p>The only concern is about normality of the errors. The qq-plot shows departures from the linear trend, and the histogram of the residuals isn’t bell-shaped.</p>
<pre class="r"><code>hist(resid(mdl_int))</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-29-1.png" width="60%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>shapiro.test(resid(mdl_int))</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(mdl_int)
## W = 0.90301, p-value = 0.001177</code></pre>
<div class="int">
<p>Furthermore, we performed a Shapiro-Wilks test against the null hypothesis that the residuals come from a normal population. The test-statistic <span class="math inline">\(W = 0.903\)</span> leads to a p-value of .001. The very small p-value indicates that the sample data provide strong evidence against the null hypothesis that the residuals came from a normal population.</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="red">
<p><strong>WARNING</strong></p>
<p>The residuals don’t look like a sample from a normal population. For this reason, we can’t trust the model results and we should not generalise the results to the population as the hypothesis tests to be valid require all the assumptions to be met, including normality.</p>
<p>We will nevertheless carry on and finish this example so that we can exploring the remaining functions relevant for carrying out a two-way ANOVA.</p>
</div>
</div>
<div id="contrast-analysis" class="section level1">
<h1>Contrast analysis</h1>
<p>We will begin by looking at each factor separately.
In terms of the diagnostic groups, recall that we want to compare the amnesiacs to the Huntington individuals.
This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively.
Similarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task.
This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks.</p>
<p>When we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:</p>
<p><img src="images/contr_interaction.png" width="100%" style="display: block; margin: auto;" /></p>
<p>This can be done in R using:</p>
<pre class="r"><code>diag_coef  &lt;- c(&#39;control&#39; = 0, &#39;amnesic&#39; = 1, &#39;huntingtons&#39; = -1)
task_coef  &lt;- c(&#39;grammar&#39; = 0.5, &#39;classification&#39; = 0.5, &#39;recognition&#39; = -1)
contr_coef &lt;- outer(diag_coef, task_coef)   # or: diag_coef %o% task_coef
contr_coef</code></pre>
<pre><code>##             grammar classification recognition
## control         0.0            0.0           0
## amnesic         0.5            0.5          -1
## huntingtons    -0.5           -0.5           1</code></pre>
<p>The above coefficients correspond to testing the null hypothesis</p>
<p><span class="math display">\[
H_0 : \frac{\mu_{2,1} + \mu_{2,2}}{2} - \mu_{2,3} - \left( \frac{\mu_{3,1} + \mu_{3,2}}{2} - \mu_{3,3} \right) = 0
\]</span></p>
<p>or, equivalently,</p>
<p><span class="math display">\[
H_0 : \frac{\mu_{2,1} + \mu_{2,2}}{2} - \mu_{2,3} = \frac{\mu_{3,1} + \mu_{3,2}}{2} - \mu_{3,3}
\]</span>
which says that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for amnesic patients and Huntingtons individuals. Note that the scores for the grammar and classification tasks have been averaged to obtain a single measure of “implicit memory” score.</p>
<p>Now that we have the coefficients, let’s call the emmeans function:</p>
<pre class="r"><code>emm &lt;- emmeans(mdl_int, ~ Diagnosis*Task)
emm</code></pre>
<pre><code>##  Diagnosis   Task           emmean   SE df lower.CL upper.CL
##  control     grammar            80 5.62 36     68.6     91.4
##  amnesic     grammar            60 5.62 36     48.6     71.4
##  huntingtons grammar            40 5.62 36     28.6     51.4
##  control     classification     80 5.62 36     68.6     91.4
##  amnesic     classification     70 5.62 36     58.6     81.4
##  huntingtons classification     45 5.62 36     33.6     56.4
##  control     recognition        95 5.62 36     83.6    106.4
##  amnesic     recognition        65 5.62 36     53.6     76.4
##  huntingtons recognition        95 5.62 36     83.6    106.4
## 
## Confidence level used: 0.95</code></pre>
<p>Next, insert the coefficients following the order specified by the rows of <code>emm</code> above. That is, the first one should be for <code>control</code> <code>grammar</code>, the second for <code>amnesic</code> <code>grammar</code>, and so on…
We also give a name to this contrast, such as ‘Research Hyp.’</p>
<pre class="r"><code>comp_res &lt;- contrast(emm, 
                     method = list(&#39;Research Hyp&#39; = c(0, 0.5, -0.5, 0, 0.5, -0.5, 0, -1, 1)))
comp_res</code></pre>
<pre><code>##  contrast     estimate   SE df t.ratio p.value
##  Research Hyp     52.5 9.73 36 5.396   &lt;.0001</code></pre>
<pre class="r"><code>confint(comp_res)</code></pre>
<pre><code>##  contrast     estimate   SE df lower.CL upper.CL
##  Research Hyp     52.5 9.73 36     32.8     72.2
## 
## Confidence level used: 0.95</code></pre>
<p>or:</p>
<pre class="r"><code>summary(comp_res, infer = TRUE)</code></pre>
<pre><code>##  contrast     estimate   SE df lower.CL upper.CL t.ratio p.value
##  Research Hyp     52.5 9.73 36     32.8     72.2 5.396   &lt;.0001 
## 
## Confidence level used: 0.95</code></pre>
<div class="question-begin">
Question 9
</div>
<div class="question-body">
<p>Interpret the results of the contrast analysis.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-160" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-160&#39;, &#39;sol-start-160&#39;)"></span>
</div>
<div id="sol-body-160" class="solution-body" style="display: none;">
<p>The contrast analysis yields a t-value of 5.4 and a corresponding p value less than .001. Thus, there is strong evidence that the contrast is not zero in the population. In other words, amnesiacs and Huntingtons differ in the difference between implicit and explicit recognition memory tasks.
Examining the cell means or, even better, the interaction plot showing the cell means (shown again below) shows that amnesiacs perform relatively better on implicit memory tasks, whereas Huntington individuals perform relatively better on explicit memory tasks, just as expected from our theory.</p>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-36-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>It may be useful to supplement this hypothesis test with some indication of effect size. The recommendation is to report a confidence interval and interpret it in the context of the study, playing attention to the sign of the interval.</p>
<p>The contrast analysis shows that the 95% confidence interval for our contrast stretches from 32.77 to 72.23. This interval does not contain zero. Thus, we can be 95% confident that the task difference is not the same for amnesiacs as for Huntingtons, which is why we can reject the null hypothesis that the difference in differences is zero.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 10
</div>
<div class="question-body">
<p>The following code compares the means of the different diagnosis groups for each task.</p>
<p>Furthermore, it adjusts for multiple comparisons using the Bonferroni method. This makes sure that the experimentwise error rate is 5%. If we do not control for multiple comparisons, the more t-tests we do, the higher the chance of wrongly rejecting the null, and across the family of t-tests performed that chance will be much higher than 5%.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<pre class="r"><code>emm_task &lt;- emmeans(mdl_int, ~ Diagnosis | Task)
emm_task</code></pre>
<pre><code>## Task = grammar:
##  Diagnosis   emmean   SE df lower.CL upper.CL
##  control         80 5.62 36     68.6     91.4
##  amnesic         60 5.62 36     48.6     71.4
##  huntingtons     40 5.62 36     28.6     51.4
## 
## Task = classification:
##  Diagnosis   emmean   SE df lower.CL upper.CL
##  control         80 5.62 36     68.6     91.4
##  amnesic         70 5.62 36     58.6     81.4
##  huntingtons     45 5.62 36     33.6     56.4
## 
## Task = recognition:
##  Diagnosis   emmean   SE df lower.CL upper.CL
##  control         95 5.62 36     83.6    106.4
##  amnesic         65 5.62 36     53.6     76.4
##  huntingtons     95 5.62 36     83.6    106.4
## 
## Confidence level used: 0.95</code></pre>
<pre class="r"><code>contr_task &lt;- contrast(emm_task, method = &#39;pairwise&#39;, 
                       adjust = &quot;bonferroni&quot;)
contr_task</code></pre>
<pre><code>## Task = grammar:
##  contrast              estimate   SE df t.ratio p.value
##  control - amnesic           20 7.94 36  2.518  0.0492 
##  control - huntingtons       40 7.94 36  5.035  &lt;.0001 
##  amnesic - huntingtons       20 7.94 36  2.518  0.0492 
## 
## Task = classification:
##  contrast              estimate   SE df t.ratio p.value
##  control - amnesic           10 7.94 36  1.259  0.6486 
##  control - huntingtons       35 7.94 36  4.406  0.0003 
##  amnesic - huntingtons       25 7.94 36  3.147  0.0099 
## 
## Task = recognition:
##  contrast              estimate   SE df t.ratio p.value
##  control - amnesic           30 7.94 36  3.776  0.0017 
##  control - huntingtons        0 7.94 36  0.000  1.0000 
##  amnesic - huntingtons      -30 7.94 36 -3.776  0.0017 
## 
## P value adjustment: bonferroni method for 3 tests</code></pre>
<pre class="r"><code>plot(contr_task)</code></pre>
<p><img src="12_factorial_anova_files/figure-html/unnamed-chunk-37-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Discuss what the plot tells us.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-161" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-161&#39;, &#39;sol-start-161&#39;)"></span>
</div>
<div id="sol-body-161" class="solution-body" style="display: none;">
<p>The plot shows the result of a pairwise comparisons of the mean score across the different diagnosis groups for a given task. The black dot displays the estimated mean of the combination of factor levels, while the blue band represents the 95% confidence interval.</p>
<p>We can also get the confidence intervals numerically using the same functions shown in the previous question:</p>
<pre class="r"><code>confint(contr_task)</code></pre>
<pre><code>## Task = grammar:
##  contrast              estimate   SE df lower.CL upper.CL
##  control - amnesic           20 7.94 36   0.0517     39.9
##  control - huntingtons       40 7.94 36  20.0517     59.9
##  amnesic - huntingtons       20 7.94 36   0.0517     39.9
## 
## Task = classification:
##  contrast              estimate   SE df lower.CL upper.CL
##  control - amnesic           10 7.94 36  -9.9483     29.9
##  control - huntingtons       35 7.94 36  15.0517     54.9
##  amnesic - huntingtons       25 7.94 36   5.0517     44.9
## 
## Task = recognition:
##  contrast              estimate   SE df lower.CL upper.CL
##  control - amnesic           30 7.94 36  10.0517     49.9
##  control - huntingtons        0 7.94 36 -19.9483     19.9
##  amnesic - huntingtons      -30 7.94 36 -49.9483    -10.1
## 
## Confidence level used: 0.95 
## Conf-level adjustment: bonferroni method for 3 estimates</code></pre>
<p>or:</p>
<pre class="r"><code>summary(contr_task, infer = TRUE)</code></pre>
<p><strong>Top plot: grammar task</strong></p>
<p>The top plot shows that the amnesic patients are significantly different from the Huntingtons individuals and perform better on the grammar score (related to implicit memory).
The control individuals perform significantly better than both the Huntingtons and the amnesic individuals on the grammar task.</p>
<p><strong>Middle plot: classification task</strong></p>
<p>In the middle plot we can see that the amnesic individuals score significantly higher than the Huntingtons patients in the classification task (also related to implicit memory).
Control individuals score significantly higher than the Huntingtons patients.
On the contrary, control individuals do not perform significantly different from amnesic patients in the classification task.</p>
<p><strong>Bottom plot: recognition task</strong></p>
<p>Amnesic patients score significantly lower than Huntingtons individuals in the recognition task (related to explicit memory).
Control individuals do nto perform significantly different from the Huntingtons.
Finally, control patients perform significantly better than amnesic patients in the recognition task.</p>
<p>Let’s now interpret the quantities of interest for our study.</p>
<div class="int">
<p>We are 95% confident that amnesic patients score between .05 and 40 higher, on average, than Huntingtons individuals in the grammar task, which is related to implicit memory.</p>
<p>In the classification task, also related to implicit memory, we are 95% confident that amnesic patients score between 5 and 45 more, on average, than Huntingtons individuals.</p>
<p>Finally, we are 95% confident that amnesic patients will score between 50 and 10 less, on average, than Huntingtons patients.</p>
</div>
</div>
<p class="solution-end">
</p>
<p><br></p>
<div class="optional-begin">
Testing all combinations (pairwise comparisons).<span id="opt-start-162" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-162&#39;, &#39;opt-start-162&#39;)"></span>
</div>
<div id="opt-body-162" class="optional-body" style="display: none;">
<p>Above, we have looked at the pairwise comparisons of the mean scores across the different diagnosis for a given task.</p>
<p>To test <strong>all</strong> pairwise combinations of means across all diagnoses and tasks, we use the following code:</p>
<pre class="r"><code>emm &lt;- emmeans(mdl_int, ~ Diagnosis*Task)
contrast(emm, method = &#39;pairwise&#39;, adjust = &quot;bonferroni&quot;)</code></pre>
<pre><code>##  contrast                                             estimate   SE df t.ratio
##  control grammar - amnesic grammar                          20 7.94 36  2.518 
##  control grammar - huntingtons grammar                      40 7.94 36  5.035 
##  control grammar - control classification                    0 7.94 36  0.000 
##  control grammar - amnesic classification                   10 7.94 36  1.259 
##  control grammar - huntingtons classification               35 7.94 36  4.406 
##  control grammar - control recognition                     -15 7.94 36 -1.888 
##  control grammar - amnesic recognition                      15 7.94 36  1.888 
##  control grammar - huntingtons recognition                 -15 7.94 36 -1.888 
##  amnesic grammar - huntingtons grammar                      20 7.94 36  2.518 
##  amnesic grammar - control classification                  -20 7.94 36 -2.518 
##  amnesic grammar - amnesic classification                  -10 7.94 36 -1.259 
##  amnesic grammar - huntingtons classification               15 7.94 36  1.888 
##  amnesic grammar - control recognition                     -35 7.94 36 -4.406 
##  amnesic grammar - amnesic recognition                      -5 7.94 36 -0.629 
##  amnesic grammar - huntingtons recognition                 -35 7.94 36 -4.406 
##  huntingtons grammar - control classification              -40 7.94 36 -5.035 
##  huntingtons grammar - amnesic classification              -30 7.94 36 -3.776 
##  huntingtons grammar - huntingtons classification           -5 7.94 36 -0.629 
##  huntingtons grammar - control recognition                 -55 7.94 36 -6.923 
##  huntingtons grammar - amnesic recognition                 -25 7.94 36 -3.147 
##  huntingtons grammar - huntingtons recognition             -55 7.94 36 -6.923 
##  control classification - amnesic classification            10 7.94 36  1.259 
##  control classification - huntingtons classification        35 7.94 36  4.406 
##  control classification - control recognition              -15 7.94 36 -1.888 
##  control classification - amnesic recognition               15 7.94 36  1.888 
##  control classification - huntingtons recognition          -15 7.94 36 -1.888 
##  amnesic classification - huntingtons classification        25 7.94 36  3.147 
##  amnesic classification - control recognition              -25 7.94 36 -3.147 
##  amnesic classification - amnesic recognition                5 7.94 36  0.629 
##  amnesic classification - huntingtons recognition          -25 7.94 36 -3.147 
##  huntingtons classification - control recognition          -50 7.94 36 -6.294 
##  huntingtons classification - amnesic recognition          -20 7.94 36 -2.518 
##  huntingtons classification - huntingtons recognition      -50 7.94 36 -6.294 
##  control recognition - amnesic recognition                  30 7.94 36  3.776 
##  control recognition - huntingtons recognition               0 7.94 36  0.000 
##  amnesic recognition - huntingtons recognition             -30 7.94 36 -3.776 
##  p.value
##  0.5907 
##  0.0005 
##  1.0000 
##  1.0000 
##  0.0033 
##  1.0000 
##  1.0000 
##  1.0000 
##  0.5907 
##  0.5907 
##  1.0000 
##  1.0000 
##  0.0033 
##  1.0000 
##  0.0033 
##  0.0005 
##  0.0207 
##  1.0000 
##  &lt;.0001 
##  0.1190 
##  &lt;.0001 
##  1.0000 
##  0.0033 
##  1.0000 
##  1.0000 
##  1.0000 
##  0.1190 
##  0.1190 
##  1.0000 
##  0.1190 
##  &lt;.0001 
##  0.5907 
##  &lt;.0001 
##  0.0207 
##  1.0000 
##  0.0207 
## 
## P value adjustment: bonferroni method for 36 tests</code></pre>
</div>
<p class="optional-end">
</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<!-- Formatting -->
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Maxwell2017" class="csl-entry">
Maxwell, Scott E, Harold D Delaney, and Ken Kelley. 2017. <em>Designing Experiments and Analyzing Data: A Model Comparison Perspective</em>. Routledge.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>
Some researchers may point out that a design where each person was assessed on all three tasks might have been more efficient. However, the task factor in such design would then be within-subjects, meaning that the scores corresponding to the same person would be correlated. To analyse such design we will need a different method which is discussed next year!<br />
<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>
Each t-test comes with a <span class="math inline">\(\alpha = 0.05\)</span> probability of Type I error (wrongly rejecting the null hypothesis). If we do 9 t-tests, we will have that the experimentwise error rate is <span class="math inline">\(\alpha_{ew} \leq 9 \times 0.05\)</span>, where 9 is the number of comparisons made as part of the experiment.
Thus, if nine independent comparisons were made at the <span class="math inline">\(\alpha = 0.05\)</span> level, the experimentwise Type I error rate <span class="math inline">\(\alpha_{ew}\)</span> would be at most <span class="math inline">\(9 \times 0.05 = 0.45\)</span>. That is, we could wrongly reject the null hypothesis up to 45 times out of 100.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<link rel="stylesheet" href="https://uoepsy.github.io/assets/css/ccfooter.css" />
<div class="ccfooter"></div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
